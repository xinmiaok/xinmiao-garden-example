---
书名: 多元统计分析及R语言建模
---

```ad-info
title: <u></u>**描述**
collapse: open
color: 233, 244, 240

**◀️ 父节点| ▶️ 子节点** 

🪁 status: #🔖 
🎏 class: #📸  

description ::  【目的要求】要求学生针对因变量和解释变量的取值性质, 了解统计模型的类型; 掌握数据的分类与模型选择方式, 并对广义线性模型和一般线性模型有初步的了解。【教学内容】数据的分类与模型选择; 广义线性模型; Logistic 回归模型; 对数线性 模型; 一般线性模型。

来源::

📎

```

实际数据通常通过观察或实验获得。
- [[因变量]]
	- 是指研究中主要关心的随机现象的数量化表现。
- [[因变量]]受诸多因素影响, 这些影响因素称为[[解释变量]]。
- **实验和观察的目的**
	- 就是探讨解释变量对因变量的<span style="background:rgba(240, 200, 0, 0.2)">影响 (效应) 大小</span>, 
	- 以及影响效应有<span style="background:rgba(240, 200, 0, 0.2)">无统计学意义</span>。
	- 根据获得的数据, 建立因变量和解释变量间恰当的<span style="background:rgba(240, 200, 0, 0.2)">统计模型</span> (关系), 解决下列三个问题:
		- (1) <span style="background:rgba(240, 107, 5, 0.2)">解释变量对因变量的效应</span>。
		- (2)<span style="background:rgba(240, 107, 5, 0.2)"> 效应有无统计学意义</span>。
		- (3)<span style="background:rgba(240, 107, 5, 0.2)">因变量随解释变量的变化规律</span>。

由于统计模型的多样性和各种模型的适应性, 针对<span style="background:rgba(163, 67, 31, 0.2)">因变量和解释变量的取值性质</span>, 统计模型可分为多种类型:
- （1）[[一般线性模型]]: 这里主要讲实验设计模型, 即自变量为==定性变量的线性模型==。
- （2）[[广义线性模型]]：包括 Logistic 回归模型、对数线性模型及 Cox 比例风险模型等。 本章重点介绍广义线性模型和一般线性模型及其 R语言使用。
## 5.1 数据的分类与模型选择
### 5.1.1 变量的取值类型
因变量记为  y , 解释变量记为  $x_{1}, x_{2}, \cdots, x_{p}, X=\left(x_{1}, x_{2}, \cdots, x_{p}\right)^{\prime}$  。

因变量  y  一般有如下五种取值方式:
- (1)  y  为[[连续变量]], 
	- 如心脏面积、肺活量、血红蛋白量等。
- (2)  y  为 0-1 变量或称[[二分类变量]], 
	- 如实验 “成功”与 “失败”, “有效”与 “无 效”; 治疗结果 “存活”与 “死亡” 等。
(3)  y  为[[有序变量]] (等级变量), 
	- 如治疗结果 “治愈” “显效” 和 “无效”; 检验结果为 $“-” \cdots+" \cdots++" \cdots+++”$  等。
- (4)  y  为[[多分类变量]], 
	- 如脑肿瘤分良性、恶性、转移瘤; 
	- 小儿肺炎分结核性、化胜性和细菌性等。
- (5)  y  为[[连续伴有删失变量]], 
	- 如某病治疗后存活时间可能有失访删失、终检删失和随机删失等。

解释变量  $x_{i}$  一般有如下三种取值方式:
- (1) $x_{i}$  为[[连续变量]], 
	- 如身高、体重等, 一般称 $x_{i}$  为==自变量或协变量==。
- (2)  $x_{i}$  为[[分类变量]], 
	- 如性别：男、女, 居住地：城市、乡镇、农村等, 称  $x_{i}$  为因素。
- (3)  $x_{i}$  为[[等级变量]], 
	- 如吸烟量: 不吸烟、  0 \sim 10  支、10 20 支、20 支以上等,  
	- $x_{i}$  可通过==评分转化为协变量, 也可以看成因素, 等级数看成因素的水平数==。

### 5.1.2 模型选择方式
#### 1.y  为连续变量
当  y  为连续变量时, 为了探讨  y  和  $x_{i}$  间的线性关系, 建立以下模型:
$$y=\beta_{0}+\beta_{1} x_{1}+\beta_{2} x_{2}+\cdots+\beta_{p} x_{p}+e=X \beta+e \quad(5-1)$$

- 其中,  e  为随机误差,  E(e)=0  。

假设观察了  n  个独立样品, 对于每一个样品有:

$$y_{i}=\beta_{0}+\beta_{1} x_{i 1}+\beta_{2} x_{i 2}+\cdots+\beta_{p} x_{i p}+e_{i} \quad i=1,2, \cdots, n$$

记  $Y=\left(y_{1}, y_{2}, \cdots, y_{n}\right)^{\prime}$ 

$$\begin{aligned}
X & =\left[\begin{array}{ccccc}
1 & X_{11} & X_{12} & \cdots & X_{1 p} \\
1 & X_{21} & X_{22} & \cdots & X_{2 p} \\
\vdots & \vdots & \vdots & \vdots & \vdots \\
1 & X_{n 1} & X_{n 2} & \cdots & X_{n p}
\end{array}\right] \\
\beta & =\left(\beta_{0}, \beta_{1}, \beta_{2}, \cdots, \beta_{p}\right)^{\prime} \\
e & =\left(e_{1}, e_{2}, \cdots, e_{n}\right)^{\prime}
\end{aligned}$$

于是对于一个样本含量为  n  的样本, 以上给出的线性方程可用矩阵表示为:

$$\left\{\begin{array}{l}
Y=X \beta+e \\
E(e)=0, \operatorname{cov}(e)=\sigma^{2} I
\end{array}\right.$$

其中，(5.1) 式被称为[[一般线性模型]]。
- (1) ==当  $x_{1}, x_{2}, \cdots, x_{p}$  均为变量时,== 
	- (5.1) 式就是上节讲的==[[线性回归模型]]==,  
	- y  为因变量观察结果向量,  
	- X  为自变量观察阵。
- (2) <span style="background:rgba(240, 200, 0, 0.2)">当  $x_{1}, x_{2}, \cdots, x_{p}$  是由因素构成的哑变量</span>时,  
	- y  为反应变量 (实验结果),  
	- X  为 设计阵。
	- (5.1) 式称为<span style="background:rgba(240, 200, 0, 0.2)">[[实验设计模型]]或[[方差分析模型]]</span>。
		- 例如,  T  表示居住地因素, 
			- 有三个水平：城市、乡镇、农村。
			- 构造哑变量  $X_{1}, X_{2} ,  X_{3}$  来描述  T  因素:
				- ![[Pasted image 20230406232622.png]]
				- 当 T 因素处于 “城市” 这个水平上,  
					- $X_{1}=1, X_{2}=X_{3}=0$ ; 
				- 当 T因素处于 “乡镇” 水 平上,  
					- $X_{1}=X_{3}=0, X_{2}=1$ ; 
				- 当  T因素处于 “农村” 这个水平上,  
					- $X_{1}=X_{2}=0, X_{3}=1$  。
- (3) 当一部分  $x_{i}$  是根据因素产生的<span style="background:rgba(240, 107, 5, 0.2)">哑变量</span>, 另一部分  $z_{i}$  是<span style="background:rgba(240, 107, 5, 0.2)">变量</span>时, (5.1) 式称为<span style="background:rgba(240, 107, 5, 0.2)">[[协方差分析模型]]</span>。此时, (5.1) 式可以写成:
	- $Y=X \beta+Z \alpha+e_{i}\quad(5-2)$
	- 其中,  X  是由哑变量构成的设计阵,  
	- Z  是由变量构成的观察阵。
	- 由此亦可看出
		- <span style="background:rgba(163, 67, 31, 0.2)">协方差分析模型</span>是回归模型和实验设计模型的<span style="background:rgba(163, 67, 31, 0.2)">混合效应模型</span>。
		- 协方差分析模型的分析重点在实验设计部分, 
		- 而回归部分是用来克服混杂变量——协变量对实验结果的影响的。

#### 2.y  为 0-1 变量
一般用 [[logistic回归模型]]来描述  y  与诸解释变量或因素之间的关系, 通过建立模型得 到解释变量对反应变量  y  的效应  O R  值。
#### 3.y  为有序变量
一般用[[累积比数模型]]和[[对数线性模型]]来描述  y  与解释变量之间, 
- 解释变量可以是[[等级变量]]或因素。
#### 4.y  为多分类变量
当  y  为[[多分类变量]]时, 
- 宜用对数线性模型和多分类 Logistic 回归模型描述  y  与  x  间的 关系, 解释变量  x  既可以是因素又可以是等级变量。
#### 5.y  为连续伴有删失变量
一般用 [[Cox比例风险模型]]描述  y  与解释变量  x  之间的关系,  x  可以是因素或变量。
## 5.2 广义线性模型
### 5.2. 1 广义线性模型概述
#### 背景及出现
由于统计模型的多样性和各种模型的适应性, 
- 针对==因变量和解释变量的取值性质==, 
	- 可将统计模型分为多种类型。
		- 通常<span style="background:rgba(240, 200, 0, 0.2)">自变量为定性变量</span>的线性模型称为[[一般线性模型]], 
			- 如 [[实验设计模型]]、[[方差分析模型]]。
		- <span style="background:rgba(3, 135, 102, 0.2)">因变量为非正态分布</span>的<span style="background:rgba(3, 135, 102, 0.2)">线性模型</span>称为[[广义线性模型]], 
			- 如 [[logistic回归模型]]、[[对数线性模型]]和 [[Cox比例风险模型]]。

- 对于[[一般线性模型]], 
	- 其基本假定
		- 是  ==y  服从正态分布==, 
		- 或至少  <span style="background:rgba(74, 82, 199, 0.2)">y  的方差  $\sigma^{2}$</span>  为有限常数。
	- 然而, 在实际研究中有些观察值明显不符合这个假定。
		- 例如, 当  y  是发病率  (y=k / n)  时, 
			-  y  服从<span style="background:rgba(74, 82, 199, 0.2)">二项分布</span>, 
			- 期望值和方差分别为  $E(y)=\pi, \operatorname{var}(y)=1 / n \times \pi(1-\pi)$ , 其方差与例数呈反比且是  $\pi$  的函数。
		- 又如, 当  y  是单位时间内的放射性计数时,  
			- y  服从 <span style="background:rgba(74, 82, 199, 0.2)">Poisson 分布</span>, 
			- 期望值和方差分别为  $E(y)=\mu$ ,  $\operatorname{var}(y)=\mu$ , 
			- 其方差是  $\mu$  的函数。
	- 实际数据中有很多资料均<span style="background:rgba(74, 82, 199, 0.2)">不符合一般线性模型的基本假定</span>。
		- 尽管也可以将频率或频数作为  y  代入[[一般线性模型]], 
		- 但拟合结果往往不能令人满意, 
			- 如
				- 出现频率的拟合值  y>1  、
				- 频数的拟合值  y<0  等不合理现象。

20 世纪 70 年代初, Wedderburn 等人在[[一般线性模型]]的基础上, 对  <span style="background:rgba(5, 117, 197, 0.2)">$\sigma^{2}$  为有限常数的假定作了进一步推广</span>, 
- 提出了
	- [[广义线性模型]] ( <span style="background:rgba(5, 117, 197, 0.2)">generalized linear model</span>) 的概念
	- 和[[拟似然函数]]（quasi-likelihood function）的方法, 
	- 用于求解满足下列条件的线性模型:

$$\begin{array}{l}
E(y)=\mu \\
m(\mu)=X \beta \\
\operatorname{cov}(y)=\sigma^{2} V(\mu)\quad(5-3)
\end{array}$$
- 其中,  
	- m  为连接函数  $m(\cdot)$  组成的向量, 
		- 将  $\mu$  转化为  $\beta$  的线性表达式,  
	- $V(\mu)$  为  $n \times n$  的 矩阵, 
		- 其中每个元素均为  $\mu$  的函数, 当各  $y_{i}$  值相互独立时,  $V(\mu)$  为对角矩阵。
	- 当  $m(\mu)=\mu ,  V(\mu)=I$  时，
		- (5.3) 式为<span style="background:rgba(5, 117, 197, 0.2)">一般线性模型</span>，
		- 也就是说，(5.3) 式包括了<span style="background:rgba(3, 135, 102, 0.2)">一般线性模型</span>。

在[[广义线性模型]]中，
- 均假定观察值  y  ==具有指数族概率密度函数==, 表达式为:

$$f(y \mid \theta, \varphi)=\exp \{[y \theta-b(\theta)] / a(\varphi)+c(y, \varphi)\}\quad(5-4)$$

- 其中,  $a(\cdot)$ 、$b(\cdot)$  和  $c(\cdot)$  是三种函数形式,  
- $\theta$  为典则参数。
- 如果给定  $\varphi$  (散布参数, 有时写作  $\left.\sigma^{2}\right.$） ,
- (5.4)  式就是具有参数  $\theta$  的[[指数族密度函数]]。以正态分布为例:

$$\begin{aligned}
f(y \mid \theta, \varphi) & =\frac{1}{\sqrt{2 \pi \sigma^{2}}} \exp \left[-(y-\mu)^{2} / 2 \sigma^{2}\right] \\
& =\exp \left\{\left(y \mu-\mu^{2} / 2\right) / \sigma^{2}-\frac{1}{2}\left[y^{2} / \sigma^{2}+\ln \left(2 \pi \sigma^{2}\right)\right]\right\}
\end{aligned}$$

与 (5.4) 式对照，可知:

$$\begin{array}{l}
\theta=\mu, b(\theta)=\mu^{2} / 2, \varphi=\sigma^{2}, a(\varphi)=\sigma^{2} \\
c(y, \varphi)=-\frac{1}{2}\left[y^{2} / \sigma^{2}+\ln \left(2 \pi \sigma^{2}\right)\right]
\end{array}$$

根据样本和  y  的函数可建立[[对数似然函数]], 并可导出  y  的期望值和方差。（详见 McCullagh P. , Nelder J. A. Generalized Linear Models. Chapman and Hall Ltd. ,1983)

#### 分布族
在[[广义线性模型]]中, 
- (5.4) 式中的==典则参数==
	- 不仅仅是  <span style="background:rgba(3, 135, 102, 0.2)">$\mu$  的函数</span>, 
	- 还是<span style="background:rgba(5, 117, 197, 0.2)">参数  $\beta_{0}, \beta_{1}, \cdots ,  \beta_{p}$  的线性表达式</span>。
	- 因此, 对  $\mu$  作变换, 则可得到下面==三种分布连接函数==的形式:
		- <span style="background:rgba(74, 82, 199, 0.2)">正态分布:  $m(\mu)=\mu=\sum \beta_{j} x_{j}$</span>
		- <span style="background:rgba(74, 82, 199, 0.2)">二项分布:  $m(\mu)=\ln \left(\frac{\mu}{1-\mu}\right)=\Sigma \beta_{j} x_{j}$</span> 
		- <span style="background:rgba(74, 82, 199, 0.2)">Poisson 分布:  $m(\mu)=\ln (\mu)=\Sigma \beta_{j} x_{j}$</span>

logistic 属于[[广义线性模型]]的一种, 
- 它是<span style="background:rgba(240, 200, 0, 0.2)">通常的正态线性模型的推广</span>, 
- 要求==响应变量只能通过线性形式依赖于解释变量==。
- 上述推广体现在以下两个方面:
	- (1) <span style="background:rgba(74, 82, 199, 0.2)">通过一个连接函数</span>, 将响应变量的期望与解释变量建立线性关系。
		- $$m(E(y))=\beta_{0}+\beta_{1} x_{1}+\beta_{2} x_{2}+\cdots+\beta_{p} x_{p}$$
	- （2）<span style="background:rgba(74, 82, 199, 0.2)">通过一个误差函数</span>，说明广义线性模型的最后一部分随机项。
- 因此, Logistic 是
	- 关于<span style="background:rgba(240, 200, 0, 0.2)">响应变量</span>为  ==0-1  定性变量的广义线性回归问题==, 
	- 且广义线性模型的<span style="background:rgba(136, 49, 204, 0.2)">分布族为二项分布</span>, 见表 5-1。

$$表 5-1\quad广义线性模型中的常用分布族$$
$$\begin{array}{c|l|l}
\hline \text { 分布 } & {\text { 函数 }} & {\text { 模型 }} \\
\hline \text { 正态( gaussian } & E(y)=X^{\prime} \beta & \text { 普通线性模型 } \\
\text { 二项(binomial) } & E(y)=\frac{\exp \left(X^{\prime} \beta\right)}{1+\exp \left(X^{\prime} \beta\right)} & \text { Logistic 模型和概率模型单位(probit)模型 } \\
\text { 泊松( poisson) } & E(y)=\exp \left(X^{\prime} \beta\right) & \text { 对数线性模型 } \\
\hline
\end{array}$$

#### 广义线性模型的R使用
在R语言中, 正态 (高斯) 分布族的[[广义线性模型]]事实上与[[线性模型]]是相同的, 即 

$\text { gm }<-\operatorname{glm}(\text { formula, family = gaussian, data })$

同线性模型

$\mathrm{fm}<-\operatorname{lm} \text { ( formula, data) }$

得到的结论是一致的, 当然, 其效率会低很多。

$$\text { 广义线性模型函数 glm() 的用法 }$$
```
glm(formula, family = gaussian, data, ...) 
```
- formula 为公式,即要拟合的模型
- family 为分布族,
	- 包括==正态分布 (gaussian)、二项分布 ( binomial) 、泊松分布 ( poisson) 和伽马分布 (gamma)==, 分布族还可以通过选项 link  =  来指定使用的连接函数
- data 为可选择的数据框

这样, 在广义线性意义下, 
- 我们不仅知道<span style="background:rgba(74, 82, 199, 0.2)">一般线性模型是广义线性模型的一个特例</span>, 
- 而且导出了处理频率资料的 Logistic 模型和处理频数资料的对数线性模型。
- 这个重要结果还说明, 
	- 虽然 logistic模型和[[对数线性模型]]都是[[非线性模型]], 
	- 即  $\mu$  和  $\beta$  呈非线性关系, 
		- 但<span style="background:rgba(74, 82, 199, 0.2)">通过连接函数</span>使  $m(\mu)$  和  $\beta$  呈线性关系, 
			- 从而使我们可以用==线性拟合的方法求解这类非线性模型==。
- 更有意义的是, 实际研究中的<span style="background:rgba(5, 117, 197, 0.2)">主要数据形式</span>
	- 无非是<span style="background:rgba(240, 107, 5, 0.2)">计量资料</span>、<span style="background:rgba(240, 107, 5, 0.2)">频率资料</span>和<span style="background:rgba(240, 107, 5, 0.2)">频数资料</span> (半计量资料实际上可以看作有序的频数资料), 
	- 因此, 掌握了[[广义线性模型]]的思想和方法, 
	- 结合有关统计软件 (如 SAS、SPSS 和 R), 
	- 就可以用统一的方法处理各种类型的统计数据。
	- 限于篇幅, 此处仅介绍 Logistic 回归模型。

### 5.2.2 Logistic回归模型
#### 1.Logistic 回归模型的定义
在[[一般线性模型]]中, 
- 反应变量  <span style="background:rgba(136, 49, 204, 0.2)">y  的值是有实际意义</span>的, 
- 并假定  $y \sim N\left(\mu, \sigma^{2}\right)$ , 
- 当 y是 <span style="background:rgba(74, 82, 199, 0.2)">二分类或  0-1  变量</span>时,  
	- y  的取值为 0 或 1 仅是名义上的, <span style="background:rgba(74, 82, 199, 0.2)">没有实际意义</span>, 
	- 此时  y  是服从 Bernoulli 分布（伯努利分布）的随机变量, 
		- 即  $y\sim b(n, p)$ , 
- 针对  ==0-1  变量, 回归模型须作一些改进==。
##### 模型推导
(1) ==回归函数应该改用==
- 限制在  [0,1]  区间内的<span style="background:rgba(5, 117, 197, 0.2)">连续曲线</span>, 而不能再沿用线性回归方程。应用较多的是 <span style="background:rgba(5, 117, 197, 0.2)">Logistic 函数</span>（也称 Logit 变换), 其形式为:

$$y=f(x)=\frac{1}{1+\mathrm{e}^{-x}}=\frac{\mathrm{e}^{x}}{1+\mathrm{e}^{x}}
$$

函数图如下所示:
![[Pasted image 20230407125649.png]]

(2) ==因变量== $y_{i}$ 本身只取  0 、 1  值, ==不适于直接作为==回归模型中的==因变量==, 
- 设  
	- P  表示  y=1  的概率,  
	- Q  表示  y=0  的概率,  
	- Q=1-P  。
	- 概率  P  是有实际意义的, 
		- 它表示  ==y  取值为 1 的可能性的大小==。
		- 假定在观察反应变量的同时, 观察了  p  个解释变量  $x_{1}, x_{2}, \cdots, x_{p}$ , 用向量  X  记作  $\left(x_{1}, x_{2}, \cdots, x_{p}\right)^{\prime}$  。
		- 与线性模型不同的是, 
			- 我们<span style="background:rgba(5, 117, 197, 0.2)">不是研究反应变量的值与解释变量之间的关系</span>, 
			- 而是研究==反应变量取某值的概率  P  与解释变量之间的关系==。
	- 实际观察结果表明, 
		- 概率  P  与解释变量之间不是呈线性关系, 而是呈 “  $\mathrm{S}$  ” 形曲线关系。
			- 这是因为概率分布函数是一条 “S” 形曲线。
				- Logistic 函数是呈 “  $\mathrm{S}$  ” 形的曲线, 见上图。
- 故此 一般<span style="background:rgba(5, 117, 197, 0.2)">用 Logistic 曲线来描述  P  与解释变量  x  之间的关系</span>。

$$P=P(y=1 \mid X)=\frac{\exp \left(\beta_{0}+\beta_{1} x_{1}+\cdots+\beta_{p} x_{p}\right)}{1+\exp \left(\beta_{0}+\beta_{1} x_{1}+\cdots+\beta_{p} x_{p}\right)}=\frac{\exp (X \beta)}{1+\exp (X \beta)}$$

对该式<span style="background:rgba(5, 117, 197, 0.2)">作 Logit 变换, 得:</span>

$$\operatorname{Logit}(y)=\ln \left(\frac{P}{1-P}\right)=\beta_{0}+\beta_{1} x_{1}+\cdots+\beta_{p} x_{p}=X \beta\quad(5.5)$$
- (5.5) 式称为 [[logistic回归模型]], 
	- 其中  $\beta_{0}, \beta_{1}, \cdots, \beta_{p}$  为待估参数。
	- 确定了它们, (5.5) 式就被确定了。
#### 2.Logistic 回归模型的参数估计
Logistic 回归模型中参数的估计量
- 最常用的是==[[极大似然估计]]== , 用 Newton-Raphson 迭代求解。
- 还有一种方法是根据[[广义线性模型]]的理论用==加权最小二乘法==迭代求解, 
- 两种方法求出的结果基本相同。下面简单介绍参数的极大似然估计法。

##### 参数的极大似然估计法
- 设  
	- y  是  0-1  变量,  
	- $x_{1}, x_{2}, \cdots, x_{p}$  是与  y  相关的变量,  n  组观测数据为  $\left(x_{1}, x_{2}, \cdots, x_{p} ; y_{i}\right)   (i=1,2, \cdots, n)$ , 
- 取  $P\left(y_{i}=1\right)=\pi, P\left(y_{i}=0\right)=1-\pi_{i}$ , 
- 则  $y_{i}$  的联合概率函数为:  
	- $P\left(y_{i}\right)=   \pi_{i}^{r_{i}}\left(1-\pi_{i}\right)^{1-y_{i}}, y_{i}=0,1 ; i=1,2, \cdots, n$  。
- 于是,  $y_{1}, y_{2}, \cdots, y_{n}$  的似然函数为:

$$L=\prod_{i=1}^{n} P\left(y_{i}\right)=\prod_{i=1}^{n} \pi_{i}^{y_{i}}\left(1-\pi_{i}\right)^{1-y_{i}}$$

对似然函数取自然对数得:

$$\begin{array}{l}
\ln L=\sum_{i=1}^{n}\left[y_{i} \ln \left(\pi_{i}\right)+\left(1-y_{i}\right) \ln \left(1-\pi_{i}\right)\right]=\sum_{i=1}^{n}\left[y_{i} \ln \frac{\pi_{i}}{1-\pi_{i}}+\ln \left(1-\pi_{i}\right)\right] \\
\frac{\partial \ln L}{\partial \beta_{i}}=0
\end{array}$$

- 运用 Newton-Raphson 迭代
	- 即可求出  $\beta_{i}$  的最大似然估计  $\hat{\beta}_{i}  和  \ln L_{\circ}$  
- 迭代初值一般取为  $\beta_{i}=0, i=1,2, \cdots, p$  。
- 在一些情况下, Newton-Raphson 迭代的收敛性不好, 
	- 可改用 ==Marquardt 改进的 Newton-Raphson 迭代法==求解。

#### 3.Logistic 回归模型中的参数检验
在求出  $\beta_{i}$  的==最大似然估计==  $\hat{\beta}_{i}$  的同时获得了 Fisher 信息阵  $I$ 。

$$I=\left\{\frac{\partial^{2} \ln L}{\partial \beta_{i} \partial \beta_{j}} \mid \hat{\beta}_{0}, \hat{\beta}_{1}, \cdots, \hat{\beta}_{p}\right\}$$

 $I$  的逆矩阵  $I^{-1}$  是  $\hat{\beta}_{i}$  的协方差矩阵。  
 - $I^{-1}$  的对角线元素  $I^{i i}$  是  $\hat{\beta}_{i}$  的方差。

$$\operatorname{var}\left(\hat{\beta}_{i}\right)=i^{i i}, \operatorname{Se}\left(\hat{\beta}_{i}\right)=\sqrt{I^{i i}}$$

##### (1)  $\hat{\beta}_{i}$  的检验。

$H_{0}: \hat{\beta}_{i}=0$

检验<span style="background:rgba(5, 117, 197, 0.2)">统计量</span>:  $Z=\frac{\hat{\beta}_{i}}{\operatorname{Se}\left(\hat{\beta}_{i}\right)} \sim N(0,1)$
- 如果  <span style="background:rgba(5, 117, 197, 0.2)">$Z<Z_{\alpha}$ , 认为  $\beta_{i}=0$</span> ; 
- 否则认为 $\beta_{i} \neq 0$  。
##### (2)  $\beta_{i}$  的可信区间。
 $\beta_{i}$  的可信区间为 $\hat{\beta}_{i} \pm Z_{\alpha} \operatorname{Se}\left(\hat{\beta}_{i}\right)$  。
#### 4.实例分析
##### 题目
【例 5-1】表 5-2 为对 45 名驾驶员的调查结果, 其中四个变量的含义分别为:  
- $x_{1}$  : 表示视力状况, 它是一个==分类变量==, 1 表示好, 0 表示有问题;
- $x_{2}$  : 年龄, <span style="background:rgba(5, 117, 197, 0.2)">数值型</span>;
- $x_{3}$  : 驾车教育, 它也是一个==分类变量==, 1 表示参加过驾车教育, 0 表示没有;
- y  : ==分类变量== (去年是否出过事故, 1 表示出过事故, 0 表示没有)。

$$\begin{array}{l}\text { 表 5-2 对 } 45 \text { 名驾驶员的调查结果 (数据在 mvstats4. xls：d5.1 中) }\\\begin{array}{cccc||cccc||cccc}\hline y & x_{1} & x_{2} & x_{3} & y & x_{1} & x_{2} & x_{3} & y & x_{1} & x_{2} & x_{3} \\\hline 1 & 1 & 17 & 1 & 0 & 1 & 68 & 1 & 0 & 0 & 17 & 0 \\0 & 1 & 44 & 0 & 0 & 1 & 18 & 1 & 1 & 0 & 45 & 0 \\0 & 1 & 48 & 1 & 0 & 1 & 68 & 0 & 1 & 0 & 44 & 0 \\0 & 1 & 55 & 0 & 1 & 1 & 48 & 1 & 0 & 0 & 67 & 0 \\1 & 1 & 75 & 1 & 0 & 1 & 17 & 0 & 1 & 0 & 55 & 0 \\1 & 0 & 35 & 0 & 1 & 1 & 70 & 1 & 0 & 1 & 61 & 1 \\1 & 0 & 42 & 1 & 0 & 1 & 72 & 1 & 0 & 1 & 19 & 1 \\0 & 0 & 57 & 0 & 1 & 1 & 35 & 0 & 0 & 1 & 69 & 0 \\1 & 0 & 28 & 0 & 0 & 1 & 19 & 1 & 1 & 1 & 23 & 1 \\1 & 0 & 20 & 0 & 0 & 1 & 62 & 1 & 0 & 1 & 19 & 0 \\0 & 0 & 38 & 1 & 1 & 0 & 39 & 1 & 1 & 1 & 72 & 1 \\1 & 0 & 45 & 0 & 1 & 0 & 40 & 1 & 0 & 1 & 74 & 1 \\1 & 0 & 47 & 1 & 0 & 0 & 55 & 0 & 1 & 1 & 31 & 0 \\0 & 0 & 52 & 0 & 1 & 0 & 68 & 0 & 0 & 1 & 16 & 1 \\1 & 0 & 55 & 0 & 0 & 0 & 25 & 1 & 0 & 1 & 61 & 1 \\\hline\end{array}\end{array}$$

试考察前三个变量$x_{1}$ 、 $x_{2}$ 、 $x_{3}$  与发生事故的关系。
- 这里,  y  是因变量。
	- 它只有两个值, 所以可以把它看作成功<span style="background:rgba(5, 117, 197, 0.2)">概率为  p  的 Bernoulli 试验的结果</span>。
	- 但是和单纯的 Bernoulli 试验不同, 
		- 这里的概率  <span style="background:rgba(5, 117, 197, 0.2)">p  为  $x_{1}$ 、 $x_{2}$ 、 $x_{3}$  的函数</span>。
		- 可以用 下面的 Logistic 回归模型进行分析:

$$\ln \left(\frac{p}{1-p}\right)=\beta_{0}+\beta_{1} x_{1}+\beta_{2} x_{2}+\beta_{3} x_{3}$$

##### logistic参数估计及检验

对例 5-1 进行计算:

```
d5.1=read. table ( "clipboard", header=T)  #读取例  5-1  数据 
logit. glm<-glm(y~x 1+x 2+x 3 , family= binomial, data= 55.1 ) #ogistic 回归模型
summary(logit. glm) \#Logistic 回归模型结果
```

$\text { Call : glm( formula= } \mathrm{y} \sim \mathrm{x} 1+\mathrm{x} 2+\mathrm{x} 3 \text {, family= binomial , data= } \mathrm{d} 5,1 \text { ) }$

$Deviance Residuals:$
$$\begin{array}{cccrr}\text { Min } & 1 Q & \text { Median } & 3 Q & \text { Max } \\ -1.564 & -0.913 & -0.789 & 0.964 & 1.600\end{array} $$
$Coefficients:$

$$
 \begin{array}{rrrrrl} & \text { Estimate } & \text { Std.Error } & \mathrm{z} \text { value } & \operatorname{Pr}(>|\mathrm{z}| \text { ) } \\ \text { (Intercept) } & 0.5976 & 0.8948 & 0.67 & 0.504 & \\ \mathrm{x} 1 & -1.4961 & 0.7049 & -2.12 & 0.034 & * \\ \mathrm{x} 2 & -0.0016 & 0.0168 & -0.10 & 0.924 & \\ \mathrm{x} 3 & 0.3159 & 0.7011 & 0.45 & 0.652 & \end{array}$$
$Signif. codes:0‘***'  0.001 *^{*} * *^{\prime} \quad 0.01 *^{\prime} \quad 0.05 `, \quad 0.1^{*}, \quad 1$

(Dispersion parameter for binomial family taken to be 1)

Null deviance: 62.183 on 44 degrees of freedom

Residual deviance: 57.026 on 41 degrees of freedom

\mathrm{AIC}: 65.03 

Number of Fisher Scoring iterations: 4

<span style="background:rgba(5, 117, 197, 0.2)">由此得到初步的 Logistic 回归模型:</span>

$$p=\frac{\exp \left(0.5976-1.4961 x_{1}-0.0016 x_{2}+0.3159 x_{3}\right)}{1+\exp \left(0.5976-1.4961 x_{1}-0.0016 x_{2}+0.3159 x_{3}\right)}$$

即  
$\operatorname{Logit}(p)=0.5976-1.4961 x_{1}-0.0016 x_{2}+0.3159 x_{3}$
- 在此模型中, 由于参数  $\beta_{2} 、 \beta_{3}$  ==没有通过检验==, 
	- 可类似于线性模型, 用 [[step]]()作==变量筛选==。

##### 逐步筛选法-变量选择

```
logit. step <- step( logit. glm, direction = "both") ＃逐步筛选法变量选择
```

$Start :  \mathrm{AIC}=65.03$

 $\begin{array}{cccc}y \sim x 1+x 2+x 3 & & \\ & \text { Df } & \text { Deviance } & \text { AIC } \\ -x 2 & 1 & 57.035 & 63.035 \\ -x 3 & 1 & 57.232 & 63.232 \\ \langle\text { none }> & & 57.026 & 65.026 \\ -x 1 & 1 & 61.936 & 67.936\end{array}$

$Step :  \mathrm{AIC}=63.03$

$\begin{array}{cccc}y \sim x 1+x 3 & & & \\ & \text { Df } & \text { Deviance } & \text { AIC } \\ -x 3 & 1 & 57.241 & 61.241 \\ \langle\text { none }> & & 57.035 & 63.035 \\ +x 2 & 1 & 57.026 & 65.026 \\ -x 1 & 1 & 61.991 & 65.991\end{array}$ 

$Step:  \mathrm{AIC}=61.24$

$y \sim x 1$

 $\begin{array}{cccc} & \text { Df } & \text { Deviance } & \text { AIC } \\ \langle\text { none }> & & 57.241 & 61.241 \\ +\times 3 & 1 & 57.035 & 63.035 \\ +x 2 & 1 & 57.232 & 63.232 \\ -x 1 & 1 & 62.183 & 64.183\end{array}$

```
summary (logit. step) #逐步筛选法变量选择结果
```

$Call : glm ( formula =  \mathrm{y} \sim \mathrm{x} 1 , family = binomial , data = d5.3)$

$Deviance Residuals:$
 
 $\begin{array}{ccccc}\text { Min } & 1 Q & \text { Median } & 3 Q & \text { Max } \\ -1.4490 & -0.8783 & -0.8783 & 0.9282 & 1.5096\end{array}$ 
 
$Coefficients :$
 $\begin{array}{ccccc} & \text { Estimate } & \text { Std. Error } & \mathrm{z} \text { value } & \operatorname{Pr}(>|\mathrm{z}|) \\ (\text { Intercept) } & 0.6190 & 0.4688 & 1.320 & 0.1867 \\ \mathrm{x} 1 & -1.3728 & 0.6353 & -2.161 & 0.0307 *\end{array}$
 
$Signif. codes :  0^‘* * * ' 0.001 ^‘*  * ' 0.01^‘* ' 0.05^‘*  * ' 0.1$ 

(Dispersion parameter for binomial family taken to be 1)

Null deviance: 62.183 on 44 degrees of freedom

Residual deviance:57. 241 on 43 degrees of freedom

AIC  : 61.241 

Number of Fisher Scoring iterations : 4

==可以看出新的回归方程为==:

$$p=\frac{\exp \left(0.6190-1.3728 x_{1}\right)}{1+\exp \left(0.6190-1.3728 x_{1}\right)}$$

*[[Signif. code]]*

##### 模型预测
对视力正常和视力有问题的司机分别作预测, 即预测发生交通事故的概率。

```
prel <- predict (logit. step, data. frame  (x 1=1)  ) #预测视力正常的司机 Logistic 回归结果 
pl<- exp (  pre1  ) /(1+\exp (  pre1  )) #预测视力正常司机发生事故概率
pre2<-predict(logit. step, data. frame  (x 1=0)  ) #预测视力有问题的司机 Logistic 回归结果 
p2<-exp (  pre2  ) /(1+\exp (  pre2  ))  #预测视力有问题的司机发生事故概率
c(p1,p2) #结果显示
```

$0.32 \quad 0.65$

可见,  $p_{1}=0.32$, $p_{2}=0.65$ , 
- 说明视力有问题的司机发生交通事故的概率是视力正常的司机的两倍以上。

注意：将==两水平定性变量作为因变量的回归模型==也不仅是这一种, 
- 这一种也不一定最合适, 但限于篇幅, 这里不再赘述。
- 如果因变量是<span style="background:rgba(5, 117, 197, 0.2)">多水平（多于两水平) 的定性变量</span>, 统计上也有处理方法（比如==多元 Logistic 回归==), 但这超出了本书的范围。

### 5.2.3 对数线性模型
对于[[广义线性模型]], 除了上面讲到的 [[logistic回归模型]]外, 还有其他的模型, 如 Poisson模型等, 这里就不详细介绍了, 只简单介绍 R 软件中  [[glm]]()  关于这些模型的使用方法。

<span style="background:rgba(5, 117, 197, 0.2)">Poisson 分布族模型和拟 Poisson 分布族模型的使用方法为</span>:

$$\begin{array}{l}
\mathrm{fm}<-\operatorname{glm}(\text { formula }, \text { family }=\text { poisson }(\operatorname{link}=\log ), \text { data }) \\
\mathrm{fm}<-\operatorname{glm}(\text { formula }, \text { family }=\text { quasipoisson }(\operatorname{link}=\log ), \text { data })
\end{array}$$

其直观概念是：

==$\ln (E(y))=\beta_{0}+\beta_{1} x_{1}+\beta_{2} x_{2}+\cdots+\beta_{p} x_{p}$==

==即  $E(y)=\exp \left(\beta_{0}+\beta_{1} x_{1}+\beta_{2} x_{2}+\cdots+\beta_{p} x_{p}\right)$==

Poisson 分布族模型和拟 Poisson 分布族模型唯一的<span style="background:rgba(5, 117, 197, 0.2)">差别</span>
- 就是: <span style="background:rgba(5, 117, 197, 0.2)">Poisson 分布族模型要求响应变量  y  是整数</span>, 
- 而拟 Poisson 分布族模型则没有这一要求。

对于列联表还可以用（多项分布) [[对数线性模型]]来描述。
- 以二维列联表为例, 只<span style="background:rgba(74, 82, 199, 0.2)">有主效应的对数线性模型</span>为:

$$\ln \left(m_{i j}\right)=\alpha_{i}+\beta_{j}+\varepsilon_{i j}$$

这相当于只有主效应  $\alpha_{i}$  和  $\beta_{j}$ , 
- 而这两个变量的效应是简单可加的。
- 但是有时<span style="background:rgba(74, 82, 199, 0.2)">两个变量在一起时会产生附加的交叉效应</span>, 这时, 相应的对数线性模型为:

$$\ln \left(m_{i j}\right)=\alpha_{i}+\beta_{j}+(\alpha \beta)_{i j}+\varepsilon_{i j}$$

由于前面对这个模型已经有所描述，这里就不重复了。

当==表格中数目代表一个变量的观测数目==时 (如例  5-2  的满意人数), 就要==考虑是否 用 Poisson 对数线性模型==。
- 例如, 例 5-2 有两个定性变量、一个定量变量的 Poisson 对数线性模型可以表示为:

$$\ln (\lambda)=\mu+\alpha_{i}+\beta_{j}+\gamma x+\varepsilon_{i j}$$

式中,  
- $\mu$  为常数项,  
- $\alpha_{i}$  和  $\beta_{j}$  为两个定性变量的主效应,  
- x  为连续变量, 而  $\gamma$  为其系数,  
- $\varepsilon_{i j}$  为残差项。
- 这里之所以对 Poisson 分布的正参数  $\lambda$  取对数, 是为了使模型左边的取值范围为整个实数轴。

【例 5-2】某企业想了解顾客对其产品是否满意, 同时还想了解不同收人的人群对 其产品的满意程度是否相同, 故进行了一次问卷调查。在随机发放的 1000 份问卷中, 收回有效问卷 792 份, 根据收人高低和满意回答得出的交叉分组数据见表  5-3  。

$$\text { 表 5-3 顾客对产品的满意度 (数据在 mvstats4. xls: } \mathrm{d} 5.2 \text { 中) }$$
$$\begin{array}{cccc}
\hline \text { 收人 } & \text { 满意 } & \text { 不满意 } & \text { 合计 } \\
\hline \text { 高 } & 53 & 38 & 91 \\
\text { 中 } & 434 & 108 & 542 \\
\text { 低 } & 111 & 48 & 159 \\
\hline \text { 合计 } & 598 & 194 & 792 \\
\hline
\end{array}$$

模型的检验过程如下：

```
#在 mvstats4. xls: d5.2  中选取A1: C7  区域, 然后拷贝
d5.2= read. table("clipboard", header= T  ) #读取例 5-2 数据
log. glm <-glm (  y~x1+x2 , family= poisson (link= log), data= d5.2) #多元对数线性模型 
summary (log. glm) #多元对数线性模型结果
```


$\text { Call: glm( formula }=\mathrm{y} \sim \mathrm{x} 1+\mathrm{x} 2 \text {, family= poisson }(\text { link }=\log \text { ), data }=\mathrm{d} 5.3 \text { ) }$

$Deviance Residuals:$

 $\begin{array}{rrrrrr}1 & 2 & 3 & 4 & 5 & 6 \\ -10.78 & 14.44 & -8.47 & -2.62 & 4.96 & -3.14\end{array}$
 
$Coefficients:$

 $\begin{array}{rrrrrr} & \text { Estimate } & \text { Std. Error } & \mathrm{z} \text { value } & \operatorname{Pr}(>|\mathrm{z}|) & \\ \text { (Intercept) } & 6.1569 & 0.1420 & 43.37 & <2 \mathrm{e}-16 & * * * \\ \text { x1 } & 0.1291 & 0.0437 & 2.96 & 0.0031 & * * \\ \text { x2 } & -1.1257 & 0.0826 & -13.62 & <2 \mathrm{e}-16 & * * *\end{array}$

(Dispersion parameter for poisson family taken to be 1)

Null deviance: 662.84 on 5 degrees of freedom

Residual deviance: 437.97 on 3 degrees of freedom AIC: 482

Number of Fisher Scoring iterations: 5

从检验结果可看出,  
- $p_{1}=0.0031<0.01$, $p_{2}<0.01$ , 
- 说明顾客收人和对企业产品的满意程度对产品有重要影响。

###  5.2.4 Logistic 与对数模型的区别和联系
#### 1.区别
Logistic 模型
- 描述的是==概率与协变量之间的关系==, 
- 描述一个属性响应变量是怎样==依赖一组解释变量==的。

对数线性模型
- 用来描述<span style="background:rgba(74, 82, 199, 0.2)">期望频数与协变量之间的关系</span>; 
- 对数线性模型关心的是<span style="background:rgba(74, 82, 199, 0.2)">属性响应变量之间的关联</span>。
- 对数线性模型中<span style="background:rgba(74, 82, 199, 0.2)">没有解释变量</span>, 是用行列因素的效应参数来表示的。
#### 2.联系

解释变量为属性变量的 Logistic 模型, 有等价的对数线性模型。

对于一个对数线性模型, 可以对其中一个响应变量构造 Logistic 来帮助解释模型。

## 5.3 一般线性模型
这里讲的一般线性模型
- 主要是指[[实验设计模型]]。
- 实验设计模型在[[方差分析]]中有重要 的应用, 在此将它进一步分类。
- 各种实验设计都有与之相应的实验设计模型, 而且它们都是模型 (5.1) 在各种设计方案下的具体形式, 下面将它们一一列举出来。

### 5.3.1 完全随机设计模型

表 5-4 是完全随机设计的实验结果, 
- 处理因素  A  有  G  个水平, 
- 实验结果是  $y_{i j}, j=   1,2, \cdots, n_{i} ; i=1,2, \cdots, G$。
- $A$ 是因素，拟合模型前先产生  G  个哑变量  $x_{1}, x_{2}, \cdots ,  x_{G}$  。
- 当实验结果是在  A  的第  i  个水平上获得的,  $x_{i}=1$ , 其他哑变量取值都为零。
	- 根据哑变量的这个特性, 模型（5.2) 简化成如下形式:

$$\begin{array}{ll}
y_{i j}=\mu+\alpha_{i}+e_{i j} & i=1,2, \cdots, G ; \quad j=1,2, \cdots, n_{i} \quad(5.6)\\
E(e)=0 & \operatorname{cov}(e)=\sigma^{2} I
\end{array}$$

- 其中  
	- $\mu$  表示观察结果  $y_{i j}$  的总体均值,  
	- $\alpha_{i}$  是哑量的系数, 称为  A  因素各水平的主效应,  
	- $e_{i j}$  是误差项。
	- 模型  (5.6)  可用矩阵表示为:

$$Y=X \beta+e$$

- 其中
	-  X  是设计阵, 元素为 0 或  1, 
	- e  是误差向量,  
	- Y  为观察结果向量,  $\beta=\left(\mu, \alpha_{1}\right. ,  \left.\alpha_{2}, \cdots, \alpha_{G}\right)^{\prime}$  。

#### 【例 5-3】各机器生产的薄板厚度有无显著差异
【例 5-3】设有 3 台机器, 用来生产规格相同的铝合金薄板。
- 现从 3 台机器生产出 的薄板中各随机抽取 5 块, 测出厚度值（见表 5-4), 试分析各机器生产的薄板厚度有无显著差异。

$$表 5-4\quad铝合金薄板的厚度$$
$$
\begin{array}{ccc}
\hline \text { 机器 } 1 & \text { 机器 } 2 & \text { 机器 } 3 \\
\hline 2.36 & 2.57 & 2.58 \\
2.38 & 2.53 & 2.64 \\
2.48 & 2.55 & 2.59 \\
2.45 & 2.54 & 2.67 \\
2.47 & 2.56 & 2.66 \\
2.43 & 2.61 & 2.62 \\
\hline
\end{array}$$

首先将表 5-4 的资料代人模型 (5.6) 得:

$$\left[\begin{array}{l}
y_{11} \\
y_{12} \\
y_{13} \\
y_{14} \\
y_{15} \\
y_{16} \\
y_{21} \\
y_{22} \\
y_{23} \\
y_{24} \\
y_{25} \\
y_{26} \\
y_{31} \\
y_{32} \\
y_{33} \\
y_{34} \\
y_{35} \\
y_{36}
\end{array}\right]=\left[\begin{array}{c}
2.36 \\
2.38 \\
2.48 \\
2.47 \\
2.43 \\
2.57 \\
2.53 \\
2.55 \\
2.54 \\
2.56 \\
2.61 \\
2.58 \\
2.64 \\
2.59 \\
2.67 \\
2.66 \\
2.62
\end{array}\right]=\left[\begin{array}{c}
\mu+1 \cdot \alpha_{1}+0 \cdot \alpha_{2}+0 \cdot \alpha_{3} \\
\mu+1 \cdot \alpha_{1}+0 \cdot \alpha_{2}+0 \cdot \alpha_{3} \\
\mu+1 \cdot \alpha_{1}+0 \cdot \alpha_{2}+0 \cdot \alpha_{3} \\
\mu+1 \cdot \alpha_{1}+0 \cdot \alpha_{2}+0 \cdot \alpha_{3} \\
\mu+1 \cdot \alpha_{1}+0 \cdot \alpha_{2}+0 \cdot \alpha_{3} \\
\mu+1 \cdot \alpha_{1}+0 \cdot \alpha_{2}+0 \cdot \alpha_{3} \\
\mu+0 \cdot \alpha_{1}+1 \cdot \alpha_{2}+0 \cdot \alpha_{3} \\
\mu+0 \cdot \alpha_{1}+0 \cdot \alpha_{3} \\
\mu+0 \cdot \alpha_{1}+1 \cdot \alpha_{1}+\alpha_{3}+0 \cdot \alpha_{3} \\
\mu+0 \cdot \alpha_{1}+1 \cdot \alpha_{2}+0 \cdot \alpha_{3} \\
\mu+0 \cdot \alpha_{1}+0 \cdot \alpha_{2}+1 \cdot \alpha_{3} \\
\mu+0 \cdot \alpha_{1}+0 \cdot \alpha_{2}+1 \cdot \alpha_{3} \\
\mu+0 \cdot \alpha_{1}+0 \cdot \alpha_{2}+1 \cdot \alpha_{3} \\
\mu+0 \cdot \alpha_{1}+0 \cdot \alpha_{2}+1 \cdot \alpha_{3} \\
\mu+0 \cdot \alpha_{1}+0 \cdot \alpha_{2}+1 \cdot \alpha_{3} \\
\mu+0 \cdot \alpha_{1}+0 \cdot \alpha_{2}+1 \cdot \alpha_{3}
\end{array}\right]+\left[\begin{array}{c}
e_{11} \\e_{12} \\e_{13} \\e_{14} \\e_{15} \\e_{16} \\e_{21} \\e_{22} \\e_{23} \\e_{24} \\e_{25} \\e_{26} \\e_{31} \\e_{32} \\e_{33} \\e_{34} \\e_{35} \\e_{36}\end{array}\right]$$

$\beta=\left(\mu, \alpha_{1}, \alpha_{2}, \alpha_{3}\right)^{\prime}$ , 所以相应的数据格式将是 (所有统计软件都是):
 $$\begin{array}{rr}Y & A \\ 2.36 & 1 \\ 2.38 & 1 \\ 2.48 & 1 \\ 2.45 & 1 \\ 2.47 & 1 \\ 2.43 & 1 \\ 2.57 & 2 \\ 2.53 & 2 \\ 2.55 & 2 \\ 2.54 & 2 \\ 2.56 & 2 \\ 2.61 & 2 \\ 2.58 & 3 \\ 2.64 & 3 \\ 2.59 & 3 \\ 2.67 & 3 \\ 2.66 & 3 \\ 2.62 & 3\end{array}$$ 

模型的  R  语言检验过程如下:

```
#在 mvstats4. xls:  d 5.3  中选取 A1:B19  区域, 然后拷贝
d5.3 = read. table ( "clipboard", header = T) #读取例 5-3 数据 
anova(lm(Y~factor(A), data =d5.3)) #完全随机设计模型方差分析
```

P<0.05 , 说明各机器生产的薄板厚度有显著差异。

### 5.3. 2 随机单位组设计模型

随机单位组设计也称随机区组设计。
- 表 5-5 是随机单位组实验结果, 
- 处理因素  A  有  G  个水平, 
 - 单位组  B  有  n  个, 看成  n  个水平, 
 - 分别产生  A  的  G  个哑变量和单位组  B  的  n  个哑变量后, 
 - 将实验结果  $y_{i j}$  表示成:

$$y_{i j}=\mu+\alpha_{i}+\beta_{j}+e_{i j} \quad i=1,2, \cdots, G ; j=1,2, \cdots, n$$

其中  
  - $\mu$  为总均数,  
 - $\alpha_{i}$  为处理因素  A  的第  i  个水平的效应;  
 - $\beta_{j}$  为第  j  个单位组的效应,  $e_{i j}$  为误差项。

 
#### 【例 5 -4】
- 使用 4 种燃料、 3 种推进器做火箭射程试验, 
- 每一种组合情况做一次试验, 
- 则得火箭射程列在表 5-5 中, 
- 试分析各种燃料  A  与各种推进器  B  对火箭射程有无显著影响。

$$
\text { 表 5-5 燃料 } A \text { 与各种推进器 } B \text { 对火箭射程的影响 }\\
$$
$$\begin{array}{l}
\begin{array}{ccccc}
\hline & A_{1} & A_{2} & A_{3} & A_{4} \\
\hline B_{1} & 582 & 491 & 601 & 758 \\
B_{2} & 562 & 541 & 709 & 582 \\
B_{3} & 653 & 516 & 392 & 487 \\
\hline
\end{array}
\end{array}$$

表 5-5 中处理因素是燃料 A , 单位组是推进器B, 把实验结果代人 (5.7), 得: 

$$\left[\begin{array}{l}
y_{11} \\y_{12} \\y_{13} \\y_{21} \\y_{22} \\y_{23} \\y_{31} \\y_{32} \\y_{33} \\y_{41} \\y_{42} \\y_{43}
\end{array}\right]=\left[\begin{array}{c}
582 \\562 \\653 \\491 \\541 \\516 \\601 \\709 \\392 \\758 \\582 \\487
\end{array}\right]=\left[\begin{array}{llllllll}
1 & 1 & 0 & 0 & 0 & 1 & 0 & 0 \\
1 & 1 & 0 & 0 & 0 & 0 & 1 & 0 \\
1 & 1 & 0 & 0 & 0 & 0 & 0 & 1 \\
1 & 0 & 1 & 0 & 0 & 1 & 0 & 0 \\
1 & 0 & 1 & 0 & 0 & 0 & 1 & 0 \\
1 & 0 & 1 & 0 & 0 & 0 & 0 & 1 \\
1 & 0 & 0 & 1 & 0 & 1 & 0 & 0 \\
1 & 0 & 0 & 1 & 0 & 0 & 1 & 0 \\
1 & 0 & 0 & 1 & 0 & 0 & 0 & 1 \\
1 & 0 & 0 & 0 & 1 & 1 & 0 & 0 \\
1 & 0 & 0 & 0 & 1 & 0 & 1 & 0 \\
1 & 0 & 0 & 0 & 1 & 0 & 0 & 1
\end{array}\right]\left[\begin{array}{c}
\mu \\
\alpha_{1} \\\alpha_{2} \\\alpha_{3} \\\alpha_{4} \\\beta_{1} \\\beta_{2} \\\beta_{3}\end{array}\right]+\left[\begin{array}{c}
e_{11} \\e_{12} \\e_{13} \\e_{21} \\e_{22} \\e_{23} \\e_{31} \\e_{32} \\e_{33} \\e_{41} \\e_{42} \\e_{43}
\end{array}\right]$$

这里相应的数据格式将是：

$$\begin{array}{rll}
Y & A & B \\
582 & 1 & 1 \\
491 & 2 & 1 \\
601 & 3 & 1 \\
758 & 4 & 1 \\
562 & 1 & 2 \\
541 & 2 & 2 \\
709 & 3 & 2 \\
582 & 4 & 2 \\
653 & 1 & 3 \\
516 & 2 & 3 \\
392 & 3 & 3 \\
487 & 4 & 3
\end{array}$$

模型的  R  语言检验过程如下:

```
#在 mvstats4. xls: d5.4  中选取 A1: C13 区域,然后拷贝
d5.4  = read. table ( "clipboard", header = T) #读取例 5-4 数据
anova(lm(Y~factor(A)+factor(B) , data = d5.4)) #随机单位组设计模型方差分析
```

$Analysis of Variance Table$

$Response: Y$

$\begin{array}{lccccc} & \text { Df } & \text { Sum Sq } & \text { Mean Sq } & \text { F value } & \operatorname{Pr}(>\mathrm{F}) \\ \text { factor(A) } & 3 & 15759 & 5253 & 0.43 & 0.74 \\ \text { factor(B) } & 2 & 22385 & 11192 & 0.92 & 0.45 \\ \text { Residuals } & 6 & 73198 & 12200 & & \end{array}$ 

由此可见, $P_{A}>0.05$ , 说明各种燃料 A对火箭射程无显著影响; $P_{B}>0.05$, 说明各种推进器B对火箭射程也无显著影响。 

## 案例分析：广义线性模型及其应用
下表是关于 40 个不同年龄（age，定量变量）和性别（sex，定性变量，用 0 和 1 分 别代表女性和男性）的人对某项服务产品的观点 (  y , 两水平定性变量, 用 1 和 0 分别代表认可与不认可）的数据。
### 一、数据管理
### 二、 R语言操作
#### 1.调入数据
将 Case4 中的数据复制, 然后在 RStudio 编辑器中执行 Case4 = read. table ("clipboard", header  =\mathrm{T})  。
#### 2.广义线性模型 (Logistic)
这里观点是因变量。它只有两个值, 所以可以把它看作成功概率为  p  的 Bernoulli 试验的结果。但是和单纯的 Bernoulli 试验不同, 这里的概率  p  为年龄  (x)  和性别  $\left(\alpha_{i}\right)$  的函数。可以假定下面的模型（称为 Logistic 回归模型）:
- $\ln \left(\frac{p}{1-p}\right)=\beta_{0}+\beta_{1} x+\alpha_{i}$ ,
- 这里  i=0 、 1  分别代表女性和男性

显然, 当概率  p  取 0 到 1 之间的值时, 方程左边在整个实数轴上变动。为了循序渐进, 先拟合没有性别作为自变量 (只有年龄  x  ) 的模型:

$\ln \left(\frac{p}{1-p}\right)=\beta_{0}+\beta_{1} x$ 
或者等价地 $p=\frac{\mathrm{e}^{\beta_{0}+\beta_{1} x}}{1+\mathrm{e}^{\beta_{0}+\beta_{1} x}}$

依靠计算机, 很容易得到  $\beta_{0}$  和  $\beta_{1}$  的估计分别为 2.3588 和 -0.0547 。拟合的模型为:

$$\ln \left(\frac{p}{1-p}\right)=2.3588-0.0547 x$$

可以看出, 
- 年龄的增长对认可有负面影响。
- 下面再加上性别变量进行拟合, 
	- 得到的 $\beta_{0}$ 、 $\beta_{1}$  和  $\alpha_{0}$ 、 $\alpha_{1}$  的估计（同样事先确定  $\alpha_{1}=0$  ） 分别为  2.9219 、-0.0556 、-1.0717  。 
- 可以看出年龄影响和男女混合时的模型（  $\left.\beta_{1}=-0.0556\right.$)  差不多,
	-  而女性相对于男性认可的可能性大  $\left(\alpha_{0}-\alpha_{1}=1.0717\right)$  。
	- 对于女性和男性, 该拟合模型为:

$$\ln \left(\frac{p}{1-p}\right)=2.9219-0.0556 \text { age }-1.0717 \operatorname{sex}$$

该案例程序如下所示:

```
Case4 = read. table ( "clipboard", header = T) ; Case4 
fm=glm(y~sex+age, family=binomial , data = Case4) ;fm
summary(fm)
attach(Case4) 
Pr=predict(fm, data. frame(list(sex , age))) #模型预测
p=exp (Pr) /(1+\exp (Pr))
cbind(sex, age,y, p)
plot(age, Pr)
detach(Case4)
```
















