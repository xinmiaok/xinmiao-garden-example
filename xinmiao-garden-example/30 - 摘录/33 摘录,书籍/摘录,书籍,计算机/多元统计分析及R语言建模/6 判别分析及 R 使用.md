---
书名: 多元统计分析及R语言建模
---

```ad-info
title: <u></u>**描述**
collapse: open
color: 233, 244, 240

**◀️ 父节点| ▶️ 子节点** 

🪁 status: #🔖 
🎏 class: #📸  

description ::  【目的要求】理解判别分析的目的、意义及其统计思想; 了解并熟悉判别分析的三 种类型, 特别是 Bayes 判别方法的统计思想; 掌握教材中给出的不同判别方法的判别规 则和判别函数的结构; 利用统计软件中的相应程序，实际计算教材中给出的习题; 熟悉 对两总体样本的距离判别法、Fisher 判别法和 Bayes 判别法的具体计算步骤, 并比较其异同。【教学内容】判别分析的目的和意义; 判别分析中所使用的几种判别尺度的定义和 基本性质，包括距离判别法、Fisher 判别法、Bayes 判别法及逐步判别法; 计算程序中有 关判别分析的算法基础。

来源::

📎

```


## 6.1 判别分析的概念
[[判别分析]] (discriminat analysis) 是==多变量统计分析==中用于判别样品所属类型的一种统计分析方法。
- 它所要解决的问题是在一些已知研究对象已经用某种方法分成若干类的情况下, 确定新的样品属于已知类别中的哪一类。

[[判别分析]]在处理问题时, 
- 通常要给出一个衡量新样品与各已知类别接近程度的==描述统计模型==, 即[[判别函数]], 
- 同时也须指定一种==判别规则==, 借以判定新样品的归属。
	- 判别规则可以是<span style="background:rgba(136, 49, 204, 0.2)">确定性</span>的, 确定新样品所属类别时, <span style="background:rgba(136, 49, 204, 0.2)">只考虑判别函数的大小</span>; 
	- 判别规则也可以是<span style="background:rgba(74, 82, 199, 0.2)">统计性</span>的, 确定新样品所属类别时用到<span style="background:rgba(74, 82, 199, 0.2)">概率性质</span>。
	- 根据判别准则的不同, 在判别分析法中前者属 <span style="background:rgba(136, 49, 204, 0.2)">Fisher 判别</span>, 后者属 <span style="background:rgba(74, 82, 199, 0.2)">Bayes 判别</span>。

所谓[[判别分析法]], 就是在已知分类的情况下, 一旦遇到新的样品, 可以利用此法选定一个判别标准, 以判定将该新样品放置于哪个类中。
- 换句话说, 
	- 事先设有数个群体, 
	- 此时, 取数个变量, 
	- 选定适当的判别标准, 
	- 即可辨别该群体的归属。
- 在此处我们想要讨论的情况, <span style="background:rgba(5, 117, 197, 0.2)">看起来与聚类分析法类似</span>, 
	- 似乎都是要将<span style="background:rgba(5, 117, 197, 0.2)">观察值分群分类</span>, 
- 但是它们的使用前提及意义是不同的。
	- **判别分析的理论基础**
		- 是根据观测到的某些指标的数据对所研究的对象<span style="background:rgba(3, 135, 102, 0.2)">建立判别函数</span>, 
		- 并<span style="background:rgba(3, 135, 102, 0.2)">进行分类</span>的一种多变量分析方法。
	- **判别分析所研究的是**
		- 已知分类的对象, 
			- 如已知健康人和冠心病人的血压、血脂资料, 依此建立判别函数, 并预测新样品的分类。

**判别分析法用途**
判别分析法用途很广, 
- 如
	- 动植物分类、
	- 医学疾病诊断、
	- 社区种类划分、
	- 气象区（或农业气象区) 划分、
	- 商品等级分类、
	- 职业能力分类以及
	- 人类考古学上年代及
	- 人种分类等均可利用。
- 例如, 
	- 在医学中, 临床医师根据患者的主诉、体征及检查结果作出诊断, 有时还须作鉴别诊断或分型、分类的诊断; 
	- 根据病人各种症状的严重程度
		- 预测病人的病症, 
		- 或某些治疗方法的疗效评估。
- 又如
	- 环境污染程度的鉴定及环保措施、劳保措施的效果评估; 
	- 流行病学中对某些疾病的早期预报; 
	- 疾病的病因学研究及影响因素的分析等。


判别分析方法较多，本章给出以下五种常用的方法:
![[Pasted image 20230411090822.png]]

## 6.2线性判别分析
最早提出合理的判别分析法者是 R. A. Fisher (1936)， 
- Fisher 提出将线性判别函数用于花卉分类上, 
	- 将花卉的各种特征（如花瓣长与宽、花萼长与宽等）
	- 利用线性组合方法变成单变量值, 再以==单值比较方法来判别事物间的差别==。

下面以两类判别为例说明之。
- 设有两类样品, 其分别含  $n_{1} 、 n_{2}$  个样品, 各测得  p  个 指标，观察值如表 6-1 所示。

设欲建立的线性判别函数 (linear discriminatory function) 为:  $Y=a_{1} X_{1}+a_{2} X_{2}+\cdots+   a_{p} X_{p}=a^{\prime} X$ , 
- 使得该判别函数能根据指标  $X_{1}, X_{2}, \cdots, X_{p}$  之值区分各样品应归属哪一类。 
- 式中,  $a_{i}(i=1,2, \cdots, p)$  称为判别系数。
- 在判别函数式建立后, 还须求得==临界值, 作为判断的标准==。

$$表  6-1 \quad判别分析数据结构表$$
$$\begin{array}{c|cccc|c}
\hline {\text { 例号 }} & {\text { 变量 }} & & & & \text { 分类 } \\
\ & X_{1} & X_{2} & \cdots & X_{p} & Y \\
\hline 1 & x_{11} & x_{12} & \cdots & x_{1 p} & 1 \\
2 & x_{21} & x_{22} & \cdots & x_{2 p} & 1 \\
\cdots & \cdots & \cdots & \cdots & \cdots & \cdots \\
n_{1} & x_{n, 1} & x_{n, 2} & \cdots & x_{n, p} & 1 \\
1 & \cdots & \cdots & \cdots & \cdots & 2 \\
2 & \cdots & \cdots & \cdots & \cdots & 2 \\
\cdots & \cdots & \cdots & \cdots & \cdots & \cdots \\
n_{2} & x_{n, 1} & x_{n, 2} & \cdots & x_{n, p} & 2 \\
\hline
\end{array}$$


图 6-1 是当  p=1  时两类判别的示意图, 
- 从中可以看到, 
	- 对单变量情形, 两类[[判别分析]]类似于两样本均值  [[t检验]], 
	- 只有当  $\mu_{1} \neq \mu_{2}$  时, 两类才能进行判别分析。
	- ![[Pasted image 20230408000707.png]]

### 1.求 Fisher 线性判别函数
#### Fisher 判别准则
- 要求各类之间的变异则尽可能地大, 
- 而各类内部的变异尽可能地小, 
- ==变异用离均差平方和==表示。用==分离度  $\lambda$==  来表示, 即要求:

$$\lambda=\frac{\left|\bar{Y}_{1}-\bar{Y}_{2}\right|}{S_{P}} \text { 或 } \lambda=\frac{\left(\bar{Y}_{1}-\bar{Y}_{2}\right)^{2}}{S_{P}^{2}}$$

其中,  
- $S_{p}^{2}$  为合并协方差矩阵,  
	- $$S_{p}^{2}=\frac{\left(n_{1}-1\right) S_{1}^{2}+\left(n_{2}-1\right) S_{2}^{2}}{n_{1}+n_{2}-2}$$, 
	- $S_{1}^{2}$  和  $S_{2}^{2}$  为各组的协方差矩阵。

#### Fisher 判别的目标
- 是选择适当的  x  的线性组合, 使得均值  $\bar{Y}_{1}  和  \bar{Y}_{2}$  之间的分离度达到最大。

#### 定理 6. 1 
线性组合  $Y=a^{\prime} X=\left(\bar{X}_{1}-\bar{X}_{2}\right)^{\prime} S_{P}^{-1} X$  对所有可能的线性系数向量  $a^{\prime}$ , 使得  $\lambda$  达到最大，且最大值为  $D^{2}=\left(\bar{X}_{1}-\bar{X}_{2}\right)^{\prime} S_{P}^{-1}\left(\bar{X}_{1}-\bar{X}_{2}\right)$  。

证明:

$$\lambda=\frac{\left(\bar{Y}_{1}-\bar{Y}_{2}\right)^{2}}{S_{P}^{2}}=\frac{\left(a^{\prime} \bar{X}_{1}-a^{\prime} \bar{X}_{2}\right)^{2}}{a^{\prime} S_{P} a}=\frac{\left(a^{\prime} d\right)^{2}}{a^{\prime} S_{P} a}$$

- 其中,  
	- $d=\bar{X}_{1}-\bar{X}_{2}$  。
- 于是,  
	- $$\max \lambda=\max \frac{\left(a^{\prime} d\right)^{2}}{a^{\prime} S_{p} a}=d^{\prime} S_{p}^{-1} d=\left(\bar{X}_{1}-\bar{X}_{2}\right)^{\prime} S_{p}^{-1}\left(\bar{X}_{1}-\bar{X}_{2}\right)=D^{2}$$ 

### 2.计算判别界值
求得  $a_{i}$  后, 代入判别函数式即得判别函数。

求判别界值  $Y_{0}$  ：把类 1、类 2 中各指标的均数分别代入判别函数式:

$$\left\{\begin{array}{l}
\bar{Y}_{1}=a^{\prime} \bar{X}_{1} \\
\bar{Y}_{2}=a^{\prime} \bar{X}_{2}
\end{array}\right.$$

然后以两均数的中点作为两类的界点:

$$Y_{0}=\frac{\bar{Y}_{1}+\bar{Y}_{2}}{2}$$

### 3.建立判别标准

$$\left\{\begin{array}{l}\text{当}  \bar{Y}_{1}<\bar{Y}_{2}  时, 若  Y<Y_{0} , 则  X \in G_{1} , 否则  X \in G_{2} ,  \\\text { 当 } \bar{Y}_{1}>\bar{Y}_{2} \text { 时, 若 } Y<Y_{0}, \text { 则 } X \in G_{2} \text {, 否则 } X \in G_{1} \text {, } \\ \text { 当 } Y=Y_{0} \text { 时, 待判。 }\end{array}\right. $$

### 【例 6-1】
根据经验, 今天和昨天的湿度差  $x_{1}$  及气温差  $x_{2}$  是预报明天下雨或不下雨的两个重要因子, 
- 试就表 6-2 的数据建立 Fisher 线性判别函数并进行判别。
- 设今天测得  $x_{1}=8.1$, $x_{2}=2.0$  ，
- 试问应该预报明天是雨天还是晴天?

$$表  6-2\quad  雨天和晴天的湿度差  x_{1}  和气温差  x_{2}$$
$$\begin{array}{crc|ccc}
\hline & {\text { 雨天 }(\mathrm{A})} && {\text { 晴天 }(\mathrm{B})}\\
\hline \text { 组别 } & x_{1} & x_{2}&\text { 组别 } & x_{1} & x_{2}\\
\hline 
1 & -1.9 & 3.2 & 2 & 0.2 & 6.2 \\
1 & -6.9 & 0.4 & 2 & -0.1 & 7.5 \\
1 & 5.2 & 2.0 & 2 & 0.4 & 14.6 \\
1 & 5.0 & 2.5 & 2 & 2.7 & 8.3 \\
1 & 7.3 & 0.0 & 2 & 2.1 & 0.8 \\
1 & 6.8 & 12.7 & 2 & -4.6 & 4.3 \\
1 & 0.9 & -5.4 & 2 & -1.7 & 10.9 \\
1 & -12.5 & -2.5 & 2 & -2.6 & 13.1 \\
1 & 1.5 & 1.3 & 2 & 2.6 & 12.8 \\
\hline
\end{array}$$

下面是用R语言进行线性判别的函数 lda

```
Ida(formula, data, ...)
formula 为一个形如 groups ~x1+x2+...  的公式框架; data 为数据框
```

```
#在 mvstats4. xls: d6. 1 中选取  A1: D21  区域, 然后拷贝
d6. 1 = read. table("clipboard", header = T) #读取例 6-1 数据 
attach(d6.1) #绑定数据
plot(x1, x2) 
text (x1, x2, G, adj=-0.5)  #标识点所属类别G}
```

![[Pasted image 20230408080129.png]]

```
library(MASS)
 (ld=lda(G~x1+x2))  #线性判别模型
```



```ad-todo
title: **P110**
collapse: open
color: 233, 243, 242
来源:: [[多元统计分析及R语言建模]] 王斌会

---
**Reference Note**

$Call:  lda(G~x1+x2)$

$Prior probabilities of groups:$

$\begin{array}{cc}
1 & 2 \\
0.5 & 0.5
\end{array}$

$Group means :$

$\begin{array}{ccc} & \mathrm{x} 1 & \mathrm{x} 2 \\ 1 & 0.92 & 2.10 \\ 2 & -0.38 & 8.85\end{array}$ 

$Coefficients of linear discriminants:$

$\begin{array}{ccc} & LD1 \\ {x} 1 & -0. 1035  \\ {x} 2 & 0.2248  \end{array}$


```

```
Z=predict(ld) #根据线性判别模型预测所属类别 
newG= Zsclass #预测的所属类别结果
cbind(G,Z$x, newG)  #显示结果
```


```ad-todo
title: **P110**
collapse: open
color: 233, 243, 242
$$\begin{array}{rrc}
G & {\text { LD1 }} & \text { newG } \\
1 & -0.28675 & 1 \\
1 & -0.39852 & 1 \\
1 & -1.29157 & 1 \\
1 & -1.15847 & 1 \\
1 & -1.95858 & 1 \\
1 & 0.94809 & 2 \\
1 & -2.50988 & 1 \\
1 & -0.47066 & 1 \\
1 & -1.06586 & 1 \\
1 & -0.06761 & 1 \\
2 & 0.17022 & 2 \\
2 & 0.49352 & 2 \\
2 & 2.03780 & 2 \\
2 & 0.38347 & 2 \\
2 & -1.24038 & 1 \\
2 & 0.24006 & 2 \\
2 & 1.42347 & 2 \\
2 & 2.01120 & 2 \\
2 & 1.40540 & 2 \\
2 & 1.33504 & 2
\end{array}$$
```

```
(tab=table(G, newG))
```

$\begin{array}{ccc} 
& {\text { newG }} \\
\mathrm{G} & 1 & 2 \\
1 & 9 & 1 \\
2 & 1 & 9 \\
\end{array}$

```
sum(diag( prop. table(tab)))) #符合率 
```

[1] 0.9

可见两类错判的各有 1 例, 判对的共有 18 例, 故判别符合率为  18 / 20=90.0 \%  。
- 以上为**回顾性考核**。
- 还可进行**前瞻考核**, 
	- 即将一些新的数据代入判别函数后, 观察其符合率。
	- 所建立的判别函数的优劣, 主要应看其前瞻性判别效果如何, 
		- 建立判别函数的目的主要是用于判别新样品，对新样品进行分类。
		- 实际建立判别函数时, 所用样本应采用大样本资料，这样所得的判别函数较稳定、可靠。

于是有线性判别函数  $y=-0.1035 x_{1}+0.2248 x_{2}$ , 
- 其图形见图  6-2  中的直线, 
	- 每组分别有 1 个点在线的另一侧。
- 线性判别的判别效果见表  6-3  。

![[Pasted image 20230410232446.png]]

$$表 6-3 线性判别的判别效果$$
$$\begin{array}{c|c|c|c}
\hline \text { 判别} & {\text { 原始分类 }} &{\text { 原始分类 }}&{\text { 合计 }} \\
\ \text {分类} & 1 & 2 & \\
\hline 1 & 9 & 1 & 10 \\
2 & 1 & 9 & 10 \\
\hline \text { 合计 } & 10 & 10 & 20 \\
\hline
\end{array}$$
$$符合率:  (9+9) / 20=90.0 \% $$

上面介绍了 ==Fisher 的两类判别==, 实际上, 当各类的协方差阵相同时, 
- Fisher 的多类判别和多类距离判别有相同的线性判别式,
-  所以此处从略, 参照本章第 3 节。

## 6.3 距离判别法
**距离判别的基本思想**是：
- 根据已知分类的数据, 
- 分别计算各类的重心, 即各组的均值。

**距离判别的准则是:** 
- 对任给的一次观测, 若它与第  i  类的重心距离最近, 就认为它来自第  i  类。

### 6.3. 1 两总体距离判别
设有两个总体 $G_{1} 、 G_{2}$ , 
- 从第一个总体中抽取  $n_{1}$  个样品, 
- 从第二个总体中抽取  $n_{2}$  个样品, 
- 对每个样品测量  p  个指标。

取任一个样品实测指标为  $X=\left(x_{1}, x_{2}, \cdots, x_{p}\right)^{\prime}$  。

分别
- 计算样品  X  到总体  $G_{1} 、 G_{2}$  的距离  $D\left(X, G_{1}\right)$  和  $D\left(X, G_{2}\right)$ , 
- 按距离最近准则判别归类, 即

$$\left\{\begin{array}{l}
\text { 当 } D\left(X, G_{1}\right)<D\left(X, G_{2}\right) \text {, 则 } X \in G_{1}, \\
\text { 当 } D\left(X, G_{1}\right)>D\left(X, G_{2}\right) \text {, 则 } X \in G_{2} \text {, } \\
\text { 当 } D\left(X, G_{1}\right)=D\left(X, G_{2}\right) \text {, 待判。 }
\end{array}\right.$$

具体而言, 设  $\mu_{1} 、 \mu_{2} 、 \Sigma_{1} 、 \Sigma_{2}$  分别为总体  $G_{1} 、 G_{2}$  的==均值向量和协方差阵==。通常采用==马氏距离==进行判别，即

$$D\left(X, G_{i}\right)=\left(X-\mu_{i}\right)^{\prime}\left(\sum_{i}\right)^{-1}\left(X-\mu_{i}\right), i=1,2$$

#### (1) 当  $\Sigma_{1}=\Sigma_{2}=\Sigma$  时
设

$$\begin{aligned}
W(X) & =D\left(X, G_{2}\right)-D\left(X, G_{1}\right) \\
& =\left(X-\mu_{2}\right)^{\prime} \Sigma^{-1}\left(X-\mu_{2}\right)-\left(X-\mu_{1}\right)^{\prime} \Sigma^{-1}\left(X-\mu_{1}\right) \\
& =2 X^{\prime} \Sigma^{-1}\left(\mu_{1}-\mu_{2}\right)-\left(\mu_{1}+\mu_{2}\right)^{\prime} \Sigma^{-1}\left(\mu_{1}-\mu_{2}\right)\\
& =2\left[X-\frac{1}{2}\left(\mu_{1}+\mu_{2}\right)\right]^{\prime} \Sigma^{-1}\left(\mu_{1}-\mu_{2}\right)\end{aligned}$$

令  $\bar{\mu}=\frac{\mu_{1}+\mu_{2}}{2}$ , 
- 则  $W(X)=b_{0}+b_{1} x$  为线性判别函数 (省略常数 2)，
- 其中,  $b_{0}=-\frac{1}{2}\left(\mu_{1}+\mu_{2}\right)^{\prime} \Sigma^{-1}\left(\mu_{1}-\mu_{2}\right)$ ,
 $b_{1}=\Sigma^{-1}\left(\mu_{1}-\mu_{2}\right)$  等价于上节的  $a^{\prime}=\left(\bar{X}_{1}-\bar{X}_{2}\right)^{\prime} S_{P}^{-1}$  ]

于是可根据  W(X)  的正负性判定所取样本的类别：

$$\left\{\begin{array}{ll}
\text { 当 } W(X)>0, & \text { 则 } X \in G_{1}, \\
\text { 当 } W(X)<0, & \text { 则 } X \in G_{2}, \\
\text { 当 } W(X)=0, & \text { 待判。 }
\end{array}\right.$$

#### （2）当  $\Sigma_{1} \neq \Sigma_{2}$  时
仍然用

$$\begin{aligned}
W(X) & =D\left(X, G_{2}\right)-D\left(X, G_{1}\right) \\
& =\left(X-\mu_{2}\right)^{\prime}\left(\Sigma_{2}\right)^{-1}\left(X-\mu_{2}\right)-\left(X-\mu_{1}\right)^{\prime}\left(\Sigma_{1}\right)^{-1}\left(X-\mu_{1}\right)
\end{aligned}$$

作为判别函数, 不过它是  X  的[[二次函数]]，
- 而不是上面那种情况下的线性函数。
- 类似地, 将两个总体的讨论推广到多个总体。

#### 【例 6-2】
某地市场上销售的电视机有多种牌子, 该地某商场从市场上随机抽取了20种牌子的电视机进行调查, 
- 其中 13 种畅销, 7 种滞销。
- 按电视机的质量评分、功能评分和销售价格（单位：百元）收集资料（见表  6-4  )，
	- 其中销售状态 1 中：“1”表示畅 “2” 表示滞销。
- 试根据该资料建立判别函数，并根据判别准则进行回判。
- 假设有一 厂商来推销其产品, 其产品的质量评分为 8.0 , 功能评分为 7.5 , 销售价格为 65 百元, 该厂产品的销售前景如何?

$$表  6-4 \quad20 种牌子电视机的销售情况$$
![[Pasted image 20230410233529.png]]
$\text { * 销售状态 } 2 \text { 的含义见例 6-3。 }$

```
#在 mvstats4. xls: d6. 2 中选取 A1: D21 区域,然后拷贝
d6. 2 = read. table ("clipboard", header = T) #读取例 6-2 数据 attach(d6.2) #绑定数据
plot(Q,C);text(Q, C, G1,adj=-0.8) 
```

![[Pasted image 20230410233635.png]]

```

plot(Q, P) ; text(Q, P, G 1, adj=-0.8)
```

![[Pasted image 20230410233738.png]]

```
plot}(C,P),text(C,P,G1,adj=-0.8)
```

![[Pasted image 20230410233805.png]]

上图分别是按 “质量评分” “功能评分” 和 “销售价格” 生成的分类图, 从中可以看到原始数据中每类样品在样本空间的分布情况。

##### 假定协方差矩阵不相等：二次判别函数 qda() 的用法


```
qda (formula, data,...)
formula:一个形如 groups~x1+x2+... 的公式框架; data: 数据框
```

```
library (MASS)
qd=qda(G1~Q+C+P) ; qd
```

$\text { Call: qda }(\mathrm{G} 1 \sim \mathrm{Q}+\mathrm{C}+\mathrm{P})$

$Prior probabilities of groups:$

$\begin{array}{cc}
1 & 2 \\
0.65 & 0.35
\end{array}$

$Group means:$

$\begin{array}{cccc} & \mathrm{Q} & \mathrm{C} & \mathrm{P} \\ 1 & 7.977 & 6.731 & 61.54 \\ 2 & 5.957 & 3.714 & 34.00\end{array}$ 

```
predict(qd)
cbind(G1, newG = predict }(qd)$class)
```

$\begin{array}{l}
\text { G1 newG } \\
{[1,] \quad 1 \quad 1} \\
{[2,] \quad 1 \quad 1} \\
{[3,] \quad 1 \quad 1} \\
{[4,] \quad 1 \quad 1} \\
{[5,] \quad 1 \quad 1} \\
{[6,] \quad 1 \quad 1} \\
{[7,] \quad 1 \quad 1} \\
{[8,] \quad 1 \quad 1} \\
{[9,] \quad 1 \quad 1} \\
{[10,] \quad 1 \quad 1} \\
{[11,] \quad 1 \quad 1} \\
{[12,] \quad 1 \quad 1} \\
{[13,] \quad 1 \quad 1} \\
{[14,] \quad 2 \quad 2} \\
{[15,] \quad 2 \quad 2} \\
{[16,] \quad 2 \quad 2} \\
{[17,] \quad 2 \quad 2} \\
{[18,] \quad 2 \quad 2} \\
{[19,] \quad 2 \quad 2} \\
{[20,] \quad 2 \quad 2} \\
\end{array}$

```
predict(qd, data. frame(Q=8,C=7.5,P=65))#判定 
```

$\$class$

$[1] 1$

$Levels: 1$

根据我们建立的[[二次判别函数]], 代入预测数据, 判断新样品属于第 1 类, 即该产品 应该比较畅销。

##### 假定协方差矩阵相等：线性判别分析
如果假定协方差矩阵相等, 就可进行[[线性判别分析]], 下面使用[[线性判别函数]]进行判别。

```
library (MASS)
ld=lda(G1~Q+C+P) ; ld }
```


$\text { Call : } \operatorname{lda}(\mathrm{G} 1 \sim Q+C+P)$

$Prior\quad probabilities\quad of\quad groups:$

$\begin{array}{cc}
1 & 2 \\
0.65 & 0.35
\end{array}$

$Group means:$

$\begin{array}{cccc} & Q & C & P \\ 1 & 7.977 & 6.731 & 61.54 \\ 2 & 5.957 & 3.714 & 34.00\end{array}$

$Coefficients\quad of\quad linear\quad discriminants:$

$\begin{array}{cc} 
& \text { LD1 } \\
\mathrm{Q} & -0.82211 \\
\mathrm{C} & -0.64614 \\
\mathrm{P} & 0.01495
\end{array}$

```
W=predict(ld) 
cbind(G1,Wx=W$x,newG=W$class)
```

$\begin{array}{cccc} 
& \text { G1 } & \text { LD1 } & \text { newG } \\
1 & 1 & -0.1070 & 1 \\
2 & 1 & -2.4487 & 1 \\
3 & 1 & -0.3569 & 1 \\
4 & 1 & -0.9914 & 1 \\
5 & 1 & -1.7445 & 1 \\
6 & 1 & -2.5102 & 1 \\
7 & 1 & 0.3574 & 1 \\
8 & 1 & -2.6388 & 1 \\
9 & 1 & -1.2305 & 1 \\
10 & 1 & -1.8499 & 1 \\
11 & 1 & -1.2579 & 1 \\
12 & 1 & -0.1244 & 1 \\
13 & 1 & 0.3532 & 1 \\
14 & 2 & 2.9416 & 2 \\
15 & 2 & 1.6046 & 2 \\
16 & 2 & 0.7642 & 2 \\
17 & 2 & 3.0877 & 2 \\
18 & 2 & 2.3163 & 2 \\
19 & 2 & 2.2697 & 2 \\
20 & 2 & 1.5655 & 2
\end{array}$

```
predict (ld, data. frame }(Q=8, C=7.5, P=65)) #判定 
```

$\$class$

$[1] 1$

$Levels:  1 \quad 2$

根据我们建立的线性判别函数, 代人预测数据, 判断新样品属于第 1 类, 即该产品 应该比较畅销。

### 6.3.2 多总体距离判别
#### 1.协方差矩阵相同
设有  k  个总体  $G_{1}, G_{2}, \cdots, G_{k}$ , 
- 它们的均值分别为  $\mu_{1}, \mu_{2}, \cdots, \mu_{k}$ , 
- 有相同的协方差矩阵  $\Sigma$ , 
- 对任一个样品实测指标  $X=\left(x_{1}, x_{2}, \cdots, x_{p}\right)^{\prime}$ , 
- 计算其到类  i  的马氏距离:

$$\begin{aligned}
D\left(X, G_{i}\right) & =\left(X-\mu_{i}\right)^{\prime} \Sigma^{-1}\left(X-\mu_{i}\right) \\
& =X^{\prime} \Sigma^{-1} X-2 \mu_{i}{ }^{\prime} \Sigma^{-1} X+\mu_{i}{ }^{\prime} \Sigma^{-1} \mu_{i} \\
& =X^{\prime} \Sigma^{-1} X-2\left(b_{i} X+b_{0}\right) \\
& =X^{\prime} \Sigma^{-1} X-2 Z_{i}
\end{aligned}$$

于是得线性判别函数  $Z_{i}=b_{0}+b_{i} X, i=1,2, \cdots, k$  。
- 其中,  $b_{0}=-\frac{1}{2} \mu_{i}{ }^{\prime} \Sigma^{-1} \mu_{i}$ , 为常数项,  
- $b_{i}=\mu_{i}{ }^{\prime} \Sigma^{-1}$ , 为线性判别系数。

相应的判别规则为：
- 当  $Z_{i}=\max _{1 \leqslant j \leqslant k}\left(Z_{j}\right)$ , 则  $X \in G_{i}$  。
- 当  $\mu_{1}, \mu_{2}, \cdots, \mu_{k}  和  \sum$  未知时, 可用样本均值向量和样本合并方差阵  $S_{p}$  估计，其中，

$$\begin{array}{l}
\hat{\Sigma}=S_{p}=\frac{1}{n-k} \sum_{i=1}^{k} A_{i}, \quad n=n_{1}+n_{2}+\cdots+n_{k} \\
A_{i}=\sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)\left(X_{i}-\bar{X}\right)^{\prime}, \quad i=1,2, \cdots, k
\end{array}$$

#### 2.协方差矩阵不同
设有  k  个总体  $G_{1}, G_{2}, \cdots, G_{k}$ , 
- 它们的均值分别为  $\mu_{1}, \mu_{2}, \cdots, \mu_{k}$ , 
- 且它们的协方差矩阵  $\sum_{i}$  不全相同, 
- 对任一个样品实测指标  $X=\left(x_{1}, x_{2}, \cdots, x_{p}\right)^{\prime}$ , 
- 计算其到类  i  的马氏距离为  $D\left(X, G_{i}\right)=\left(X-\mu_{i}\right)^{\prime} \sum_{i}^{-1}\left(X-\mu_{i}\right), i=1,2, \cdots, k_{\text {。 }}$  
- 由于各  $\Sigma_{i}$  不同, 所以从该式推导不出线性判别函数, 因其本身是一个二次函数。

相应的判别规则为:
- 当  $D\left(X, G_{i}\right)=\min _{1 \leqslant j \leqslant k} D\left(X, G_{j}\right)$ , 则  $X \in G_{i}$  。
- 当  $\mu_{1}, \mu_{2}, \cdots, \mu_{k}$  和  $\Sigma_{1}, \Sigma_{2}, \cdots, \Sigma_{k}$  未知时, 样本均值向量的估计同前。

#### 【例 6-3】
(续例 6-2) 在例 6-2 抽取的 20 种牌子的 13 种畅销电视机中, 
- 实际只 有 5 种真正畅销, 
- 8 种是平销, 
- 另外 7 种滞销。
- 按电视机的质量评分、功能评分和销售价格（单位：百元）收集资料（见表  6-4  ）, 
	- 其销售状态  G 2  分 3 种: “1”表示畅销、“2” 表示平销、“3” 表示滞销。
- 试根据此资料建立判别函数, 并根据判别准则进行回判。

##### 生成分组图
```
d6.3=read. table("clipboard", header=T)#  读取例  6-3  数据 
attach(d6.3) #绑定数据
plot(Q, C) ; text(Q, C, G 2, adj=-0.8, cex=0.75)
```

![[Pasted image 20230411074318.png]]

```
plot(Q, P); text(Q, P, G 2, adj=-0.8, cex =0.75)
```

![[Pasted image 20230411074411.png]]

```
plot(C,P) ; text(C,P,G2,adj=-0.8, cex=0.75)
```

![[Pasted image 20230411074452.png]]

上图分别是按 “质量评分” “功能评分” 和 “销售价格” 生成的分组图，从中可以看出原始数据中每类样品在样本空间的分布情况。

#### 3. 线性判别 (等方差)

```
ld=lda(G~Q+C+P) ;ld 
```


$Call:$

$\text { lda }(\mathrm{G} 2 \sim \mathrm{Q}+\mathrm{C}+\mathrm{P})$


$Prior\quad probabilities\quad of\quad groups:$

$\begin{array}{ccc}1 & 2 & 3 \\ 0.25 & 0.40 & 0.35\end{array}$

$Group means :$

$\begin{array}{cccc} & Q & C & P \\ 1 & 8.40 & 5.90 & 48.2 \\ 2 & 7.71 & 7.25 & 69.9 \\ 3 & 5.96 & 3.71 & 34.0\end{array}$ 

$Coefficients \quad of \quad linear \quad discriminants :$

$\begin{array}{ccr} 
& { LD1 } & { LD2 } \\
Q & -0.8117 & 0.8841 \\
C & -0.6309 & 0.2013 \\
P & 0.0158 & -0.0878
\end{array}$

$Proportion \quad of \quad trace:$

$LD1 \quad LD2$

$0.74 \quad 0.26$

```
Z=predict (Id ) 
newG=Z$class
cbind(G2, Z$x, newG)
```

$\begin{array}{lrrrr} 
& \text { G2 } & {\text { LD1 }} & \text { LD2 } & \text { newG } \\
1 & 1 & -0.141 & 2.583 & 1 \\
2 & 1 & -2.392 & 0.825 & 1 \\
3 & 1 & -0.370 & 1.642 & 1 \\
4 & 1 & -0.971 & 0.548 & 1 \\
5 & 1 & -1.713 & 1.247 & 1 \\
6 & 1 & -2.459 & 1.362 & 1 \\
7 & 1 & 0.379 & -2.200 & 2 \\
8 & 1 & -2.558 & -0.467 & 2 \\
9 & 1 & -1.190 & -0.413 & 2 \\
10 & 1 & -1.764 & -2.382 & 2 \\
11 & 1 & -1.187 & -2.486 & 2 \\
12 & 1 & -0.112 & -0.599 & 2 \\
13 & 1 & 0.340 & 0.233 & 3 \\
14 & 2 & 2.846 & 0.937 & 3 \\
15 & 2 & 1.559 & 0.026 & 3 \\
16 & 2 & 0.746 & -0.209 & 3 \\
17 & 2 & 3.006 & -0.359 & 3 \\
18 & 2 & 2.251 & 0.009 & 3 \\
19 & 2 & 2.211 & -0.331 & 3 \\
20 & 2 & 1.521 & 0.036 & 3
\end{array}$

```
(tab=table(G2,newG))
```

$\begin{array}{l}
\text { newG }\\
\begin{array}{llll}
\mathrm{G} 2 & 1 & 2 & 3 \\
1 & 5 & 0 & 0 \\
2 & 1 & 6 & 1 \\
3 & 0 & 0 & 7
\end{array}
\end{array}$

```
diag(prop. table(tab,1))
```

$\begin{array}{lcc}
1 & 2 & 3 \\
1.00 & 0.75 & 1.00
\end{array}$

```
sum(diag(prop.table(tab,1)) 
```

${[1]\quad 0.9} \\$

```
plot(Z$x) 
text(Z$x[,1], Z$x[,2],G2,adj=-0.8, cex=0.75)
```

![[Pasted image 20230411080502.png]]

只有两个样品判错, 判别符合率: $(5+6+7) / 20=90.00 \%$ , 判别效果还是可以的 

```
predict (ld, data. frame  (Q=8, C=7.5, P=65))  #判定
$  class
[1] 2
Levels:  1  2  3 
```

根据我们建立的线性判别函数, 代入预测数据, 判断新样品属于第 2 类, 即该产品 实陒上属于平销。
#### 4.二次判别（异方差）
当协方差矩阵不相同时, 距离判别函数为非线性形式, 一般为二次函数, 方程较为复杂，结果末显示。

```
(qd=qda(G~Q+C+P))
```

$\begin{array}{l}
\text { Call: } \\
\text { qda }(G 2 \sim Q+C+P)
\end{array}$

$Prior\quad probabilities \quad of \quad groups:$

$\begin{array}{ccc}
1 & 2 & 3 \\
0.25 & 0.40 & 0.35
\end{array}$

$Group means:$

$\begin{array}{cccc} & Q & C & P \\ 1 & 8.40 & 5.90 & 48.2 \\ 2 & 7.71 & 7.25 & 69.9 \\ 3 & 5.96 & 3.71 & 34.0\end{array}$ 

```
Z=predict (qd) 
newG=Z$class 
cbind(G2,new G)
```

$\begin{array}{ccc}&\text { G2 } & \text { new }\\
{[1,]} & 1 & 1\\
{[2,]} & 1 & 1 \\
{[3,]} & 1 & 1 \\
{[4,]} & 1 & 1 \\
{[5,]} & 1 & 1 \\
{[6,]} & 2 & 1 \\
{[7,]} & 2 & 2 \\
{[8,]} & 2 & 2 \\
{[9,]} & 2 & 2 \\
{[10,]} & 2 & 2 \\
{[11,]} & 2 & 2 \\
{[12,]} & 2 & 2 \\
{[13,]} & 2 & 3 \\
{[14,]} & 3 & 3 \\
{[15,]} & 3 & 3 \\
{[16,]} & 3 & 3 \\
{[17,]} & 3 & 3 \\
{[18,]} & 3 & 3 \\
{[19,]} & 3 & 3 \\
{[20,]} & 3 & 3
\end{array}$

```
(tab=table(G2, newG))
```

$\begin{array}{cccc}
\text { newG }\\
\text { G2 } & 1 & 2 & 3 \\
1 & 5 & 0 & 0 \\
2 & 0 & 7 & 1
\end{array}$

```
sum(diag}(prop. table (tab)))
```

$[1] \quad 0.95$

判别符合率:  $(5+7+7) / 20=95.0 \%$

由判别符合率知，应用距离判别（二次判别）法进行判别的效果好于一次判别的。

```
predict (ld, data. frame  (Q=8, C=7.5, P=65))  #判定
```
$\$class$

$[1]\quad 2$

$Levels:  1 \quad 2 \quad 3$ 

根据我们建立的二次判别函数, 代入预测数据, 判断新样品属于第 2 类, 即该产品 实际上属于平销。

## 6.4 Bayes 判别法
### 6.4.1 Bayes 判别准则
上面讲的几种判别分析方法计算简单、结论明确, 比较实用。
- 但也存在两个缺点: 
	- 一是==判别方法与总体各自出现的概率大小完全无关==; 
	- 二是==判别方法与错判后造成的损失无关==, 
- 这是不尽合理的。Bayes 判别则是考虑了这两个因素而提出的一种判别方法。

Bayes 判别
- 对多个总体的判别考虑的不只是<span style="background:rgba(3, 135, 102, 0.2)">建立判别式</span>, 
- 还要计算新样品属于各总体的<span style="background:rgba(3, 135, 102, 0.2)">条件概率</span>  $p(j / x), j=1,2, \cdots, k$  。
- 比较这  k  个概率的大小, 
- 然后判定新样品归属于概率最大的总体。
- Bayes 判别准则是<span style="background:rgba(136, 49, 204, 0.2)">以个体归属于某类的概率（或某类的判别函数值）最大或错判总平均损失最小为标准的</span>。

设
- 有  k  个总体 $G_{1}, G_{2}, \cdots, G_{k}$ , 
- 它们的==先验概率== (prior probabilities) 分别为  $q_{1}, q_{2}, \cdots ,  q_{k}$  。
- 各总体的==密度函数==分别为  $p_{1}(x), p_{2}(x), \cdots, p_{k}(x)$, 
- x  为一个观测样品, 
- 该样品来自第  k  个总体的后验概率为 (Bayes 公式):

$$p(j / x)=\frac{q_{j} p_{j}(x)}{\sum_{i=1}^{k} q_{i} p_{i}(x)} \quad j=1,2, \cdots, k$$

当  $p(j / x)=\max _{1 \leqslant j \leqslant k} p(j / x)$  时, 
- 判  x  来自第  j  总体。

有时还可以使用错判损失最小的概念作判别函数，这时把将  x  错判为第  j  总体的平均 损失定义为：

$$E(g / x)=\sum_{j \neq i} \frac{q_{j} p_{j}(x)}{\sum_{i=1}^{k} q_{i} p_{i}(x)} L(g / j)$$

- 其中,  $L(g / j)$  称为损失函数, 
	- 它表示将本来是第  j  总体的样品错判为第  g  总体的损 失。
- 显然, 上式是对损失函数依概率加权平均, 或称为错判的平均损失。
- 当  $g=j$  时, 有  $L(g / j)=0$ ; 
- 当  $g \neq j$  时，有  $L(g / j)>0$  。
- 建立判别准则为:
	- 当  $E(g / x)=\min _{1 \leqslant j \leqslant k} E(j / x)$ 时, 
	- 判  x  来自第  g  总体。

从理论上讲, 考虑损失函数更为合理, 但实际中  $L(g / j)$  并不容易确定, 所以通常假定各种错判的损失皆相同，即

$$L(g / j)=\left\{\begin{array}{ll}
0 & g=j \\
1 & g \neq j
\end{array}\right.$$

于是, 寻找  g  使后验概率最大和使错判的平均损失最小是等价的, 即

$$p(g / x) \stackrel{g}{\longrightarrow} \max \Leftrightarrow E(g / x) \stackrel{g}{\longrightarrow} \min$$

### 6.4.2 正态总体的 Bayes 判别
#### 1.Bayes 判别函数的求解过程
设  k  个总体  $G_{1}, G_{2}, \cdots, G_{k}$  均服从  p  维正态分布，各总体的密度函数分别为:

$$p_{j}(x)=(2 \pi)^{-p / 2}\left|\Sigma_{j}\right|^{-1 / 2} \exp \left[-\frac{1}{2}\left(x-\mu_{j}\right)^{\prime} \Sigma_{j}^{-1}\left(x-\mu_{j}\right)\right]$$

式中, $\mu_{j}$  和  $\sum_{j}$  分别是第  j  个总体的均值向量和协方差矩阵。为了进行判别, 需在  $q_{j} p_{j}(x)$  中找出最大者, 为了使判别函数具有简单的形式, 取对数得:

$$\ln \left[q_{j} p_{j}(x)\right]=\ln q_{j}-\frac{1}{2} \ln (2 \pi)^{p}-\frac{1}{2} \ln \left|\Sigma_{j}\right|-\frac{1}{2} x^{\prime} \Sigma_{j}^{-1} x-\frac{1}{2} \mu_{j}^{\prime} \Sigma_{j}^{-1} \mu_{j}+x^{\prime} \Sigma_{j}^{-1} \mu_{j}$$

略去等式右边与  j  无关的项，记为:

$$Z(j / x)=\ln q_{j}-\frac{1}{2} \ln \left|\Sigma_{j}\right|-\frac{1}{2} x^{\prime} \sum_{j}^{-1} x-\frac{1}{2} \mu_{j}^{\prime} \sum_{j}^{-1} \mu_{j}+x^{\prime} \Sigma_{j}^{-1} \mu_{j}$$

显然，该函数是一个二次函数，其 Bayes 问题化为:

$$Z(j / x) \stackrel{j}{\longrightarrow} \max$$

根据 Bayes 准则得, 当  $Z(j / x)=\max _{1 \leqslant j \leqslant k} Z(j / x)$  时, 判  x  来自第  j  总体。
#### 2.协方差矩阵相等情形
当  k  个总体的协方差矩阵相同, 即  $\Sigma_{1}=\Sigma_{2}=\cdots=\Sigma_{k}=\Sigma  时,  Z(j / x)$  中,  
- $-\frac{1}{2} \ln \left|\Sigma_{j}\right|$ 
和  $-\frac{1}{2} x^{\prime} \Sigma_{j}^{-1}x$  与  j  无关, 求最大值时可以去掉, 这时的判别函数记为:

$$Y(j / x)=\ln q_{j}-\frac{1}{2} \mu_{j}^{\prime} \Sigma^{-1} \mu_{j}+x^{\prime} \Sigma_{j}^{-1} \mu_{j}$$

该函数是一个线性函数, 我们注意到, 该函数与前面的线性判别函数只相差一个常数  \ln $q_{i}$ , 此时 Bayes 问题化为:

$$Y(j / x) \stackrel{j}{\longrightarrow} \max$$

根据 Bayes 准则得, 
- 当  $Y(j / x)=\max _{1 \leqslant j \leqslant k} Y(j / x)$ 时, 
	- 判  x  来自第  j  总体。

上式判别函数也可写成多项式形式:

$$\begin{array}{c}
Y(j / x)=\ln q_{j}+c_{0 j}+\sum_{i=1}^{p} c_{i j} x_{i} \\
\text { 其中, } c_{i j}=\sum_{i=1}^{p} \sigma^{i l} \mu_{l j} \quad i=1,2, \cdots, p, \Sigma=\left(\sigma_{i l}\right)_{p \times p}, \Sigma^{-1}=\left(\sigma^{i l}\right)_{p \times p}, \\
c_{o j}=-\frac{1}{2} \mu_{j}^{\prime} \Sigma^{-1} \mu_{j}=-\frac{1}{2} \sum_{i=1}^{p} c_{i j} \mu_{i j}
\end{array}$$

至于先验概率  $q_{j}$ , 
- 如果没有更好的办法确定, 可用样本频率  $n_{j} / n$  来代替, 
	- 其中,  $n_{j}$  
		- 是第  j  个分类的数目, 且  $n_{1}+n_{2}+\cdots+n_{k}=n$  。
- 若取  $q_{1}=q_{2}=\cdots=q_{k}=1 / k$ , 
	- 则此时的 Bayes 判别等价于 Fisher 判别，只是相差一个常数而已。

当对  k  个分类样本, 若各类总体都服从==多元正态分布==, 并且各类总体的==协方差矩阵 相同==，上式也可写成显式的线性判别函数:

$$\left\{\begin{array}{c}
Y_{(1)}=\ln q_{1}+c_{01}+c_{11} x_{1}+c_{21} x_{2}+\cdots+c_{p_{1}} x_{p} \\
Y_{(2)}=\ln q_{2}+c_{02}+c_{12} x_{1}+c_{22} x_{2}+\cdots+c_{p_{2}} x_{p} \\
\vdots \\
Y_{(k)}=\ln q_{k}+c_{0 k}+c_{1 k} x_{1}+c_{2 k} x_{2}+\cdots+c_{p k} x_{p}
\end{array}\right.$$

若有某观察对象, 把实际测得的各指标  x  值代人上式, 可求得各类的  Y  值, 哪个  Y 值最大, 就判断其归属于哪一类。

#### 3.后验概率的计算
作判别分类时, 
- 主要是根据判别式  $y(j / x)$  的大小来分类的, 
- 但它并不是后验概率  $p(j / x)$ , 
- 我们推导  $y(j / x)$  是省略了 $\ln \left[q_{j} p_{j}(x)\right]$  中与  j  无关的项得到的, 
	- 即  $\ln \left[q_{j} p_{j}(x)\right]=y(j / x)+\delta(x)$  。这里,  $\delta(x)$  是与  j  无关的部分, 于是有 :

$$\begin{aligned}
p(j / x) & =\frac{q_{j} p_{j}(x)}{\sum_{i=1}^{k} q_{i} p_{i}(x)}=\frac{\exp [y(j / x)+\delta(x)]}{\sum_{i=1}^{k} \exp [y(i / x)+\delta(x)]} \\
& =\frac{\exp [y(j / x)] \exp [\delta(x)]}{\sum_{i=1}^{k} \exp [y(i / x)] \exp [\delta(x)]}=\frac{\exp [y(j / x)]}{\sum_{i=1}^{k} \exp [y(i / x)]}
\end{aligned}$$

由于上式使  y  最大的  j , 其  $p(j / x)$  必为最大, 因此我们只需把样品代入判别式中进行判别即可。

#### 【例 6-4】( 续例  6-3  ) 对例 6-3 数据应用 Bayes 判别法进行判别

在进行 Bayes 判别时, 假定各类协方差矩阵相同, 此时判别函数为线性函数。

##### (1) 先验概率相等: 
取  $q_{1}=q_{2}=q_{3}=1 / 3$ , 此时判别函数等价于 Fisher 线性判别函数。

```
(ld1=lda(G2~Q+C+P, prior  =c(1,1,1) / 3))  #先验概率相等的 Bayes 判别模型
 ```
 
$Call:$

$\mathrm{lda}(\mathrm{G} 2 \sim \mathrm{Q}+\mathrm{C}+\mathrm{P} , prior  =\mathrm{c}(1,1,1) / 3)$

$Prior\quad probabilities\quad of\quad groups:$

$\begin{array}{ccc}1 & 2 & 3 \\ 0.333 & 0.333 & 0.333\end{array}$

$Group\quad means:$

$\begin{array}{cccc} & Q & C & P \\ 1 & 8.40 & 5.90 & 48.2 \\ 2 & 7.71 & 7.25 & 69.9 \\ 3 & 5.96 & 3.71 & 34.0\end{array}$ 
 
$Coefficients of linear discriminants :$

$\begin{array}{ccr} 
& LD1 & {LD2 } \\
Q & -0.9231 & 0.7671 \\
 \mathrm{C}  & -0.6522 & 0.1148 \\
 \mathrm{P}  & 0.0274 & -0.0848
\end{array}$

$Proportion of trace:$

$\begin{array}{rc}\text { LD1 } & \text { LD2 } \\ 0.726 & 0.274\end{array}$

##### (2) 先验概率不等: 
取  $q_{1}=5 / 20, q_{2}=8 / 20, q_{3}=7 / 20$, 下面为先验概率不相等时 的 Bayes 判别函数的系数。

```
 (  ld  2=lda(G2~Q+C+P , prior=c(5,8,7) / 20)) #先验概率不相等的 Bayes 判别模型
 ```
 
$Call : Ida  (\mathrm{G} 2 \sim \mathrm{Q}+\mathrm{C}+\mathrm{P} , prior  =\mathrm{c}(5,8,7) / 20)$

$Prior probabilities of groups:$

$\begin{array}{ccc}1 & 2 & 3 \\ 0.25 & 0.40 & 0.35\end{array}$

$Group means :$

$\begin{array}{cccc} & Q & C & P \\ 1 & 8.40 & 5.90 & 48.2 \\ 2 & 7.71 & 7.25 & 69.9 \\ 3 & 5.96 & 3.71 & 34.0\end{array}$

$Coefficients\quad of\quad linear\quad discriminants :$

$\begin{array}{ccc} & \text { LD1 } & \text { LD2 } \\ \text { Q } & -0.8117 & 0.8841 \\ \mathrm{C} & -0.6309 & 0.2013 \\ \mathrm{P} & 0.0158 & -0.0878\end{array}$ 
 
$Proportion\quad of \quad trace:$

$LD1\quad LD2$

$0.74 \quad 0.26$

下面是两种结果比较:
![[Pasted image 20230411084313.png]]
由判别符合率知, 应用 Bayes 判别函数进行判别的效果还是不错的。
![[Pasted image 20230411084405.png]]

==后验概率给出了样品落在哪个类的概率大小==, 这也是 Bayes 判别区别于 Fisher 判别的主要特点。

```
predict ( ld1, data. frame  (Q=8, C=7.5, P=65)) # l d 1  模型的判定
```
$\$class$

[1]2

$Levels:  1 \quad 2 \quad 3$ 

$\$posterior$

$\begin{array}{cccc}
& 1 & 2 &3 \\
1 & 0.211 & 0.787 & 0.00178
\end{array}$

根据我们建立的 Bayes 判别函数, 代入预测数据, 判断新样品属于第 2 类, 
- 即该产品实际上属于平销, 
- 但属于平销的概率高于线性判别的  $69.8 \%$ , 达到  $78.7 \%$ , 
- 从这也可以看出考虑与不考虑先验概率对模型的判别效果还是有影响的。
#### 4.判别分析小结

(1) 判别分析方法
- 首先根据已知所属组的样本给出==判别函数==, 
- 并制定==判别规则==, 
- 然后再==判断==每一个新样品应属于哪一组。
- 常用的判别方法有<span style="background:rgba(136, 49, 204, 0.2)">距离判别法、Bayes 判别法、典型判别法</span>等。

(2) 判别分析中各种误判的后果允许看作是相同的, 
- 而在假设检验中, 犯两类错误的后果一般是不同的, 通常将犯第一类错误的后果看得更严重些。

(3) 判别变量
- 距离判别和 Fisher 判别
	- 对判别变量的分布类型并无要求, 
- 两者只要求各类总体的二阶矩存在, 
	- 而 Bayes 判别则要求知道判别变量的分布类型。
	- 因此, 距离判别和 Fisher 判别比 Bayes 判别简单一些。

（4）协方差矩阵
- 当仅有两个总体时, 
	- 若它们的协方差矩阵相同, 则距离判别和 Fisher 判别等价。
	-  当判别变量服从正态分布时, 它们还和 Bayes 判别等价。
- 而当两类的协方差矩阵不同时, 
	- 如 Fisher 判别用的是它们的合并协方差阵, 
	- 这时距离判别和 Bayes 判别是不同的。
## 案例分析：企业财务状况的判别分析
对 21 个破产的企业收集它们在破产前两年的财务数据, 对 25 个财务良好的企业也收集同一时期的数据。
- 数据涉及四个变量：
	- CF_TD（现金流量/总债务); 
	- NI_TA（净收 人/总资产)；
	- CA_CL (流动资产/流动债务);
	-  CA_NS (流动资产/净销售额）,
- 一个分组变量：企业现状（1：非破产企业，2：破产企业)。
- 数据见下图。
### 一、数据管理
### 二、 R语言操作
#### 1.调入数据
将 Case5 中的数据复制, 然后在 RStudio 编辑器中执行 Case5 = read. table ("clipboard", header  =\mathrm{T}  )
#### 2. Fisher 判别效果 (等方差, 线性判别 lda)
$$\text {  }\begin{array}{l}
\begin{array}{c|rcc}
\hline {\text { 原分类 }} & {\text { 新分类 }} \\
 & 1 & 2 & \text { 合计 } \\
\hline 1 & 24 & 1 & 25 \\
2 & 3 & 18 & 21 \\
\hline \text { 合计 } & 27 & 19 & 46 \\
\hline
\end{array}\\
\text { 符合率 } 91.30 \% \text { 。 }
\end{array}$$
#### 3. Fisher 判别效果 ( 异方差, 非线性判别一二次判别 qda)
$$\begin{array}{l}
\begin{array}{c|rcc}
\hline {\text { 原分类 }} & {\text { 新分类 }} \\
 & 1 & 2 & \text { 合计 } \\
\hline 1 & 24 & 1 & 25 \\
2 & 2 & 19 & 21 \\
\hline \text { 合计 } & 26 & 20 & 46 \\
\hline
\end{array}\\
\text { 符合率 } 93.5 \% \text { 。 }
\end{array}$$

qda (非线性判别——二次判别）的效果比 lda（一次判别）要好。上面我们都采用 Bayes 方式, 即先验概率是使用样本例数计算的。该案例程序如下所示:

![[Pasted image 20230411085903.png]]

一、思考题（手工解答, 上交作业本)
1. 判别分析的基本思想是什么?
2. Fisher 判别的基本思想是什么?
3. 距离判别的基本思想是什么?
4. Bayes 判别的基本思想是什么?